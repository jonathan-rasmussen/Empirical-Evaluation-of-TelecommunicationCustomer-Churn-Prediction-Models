{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SYDE675_Gr11_Project_c2c.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-5b560WTsxf"
      },
      "source": [
        "# SYDE 675 - Final Project\n",
        "\n",
        "**Winter 2021 - Group 11**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZplN6F2Ikby"
      },
      "source": [
        "# Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX8_DVGaJkF1",
        "outputId": "eb8c8228-5ec7-4d09-84f7-d07e87fbff00"
      },
      "source": [
        "# upgrade sklearn and imblearn to avoid errors\n",
        "!pip install --upgrade scikit-learn imbalanced-learn torchsummary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.5MB/s \n",
            "\u001b[?25hCollecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/98/dc784205a7e3034e84d41ac4781660c67ad6327f2f5a80c568df31673d1c/imbalanced_learn-0.8.0-py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 45.1MB/s \n",
            "\u001b[?25hRequirement already up-to-date: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn, imbalanced-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.8.0 scikit-learn-0.24.1 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3r7yJc5IkFA"
      },
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import random\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from scipy import stats\n",
        "from imblearn.over_sampling import RandomOverSampler,BorderlineSMOTE, SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCOudeUXaUgw"
      },
      "source": [
        "# Download the Dataset\n",
        "\n",
        "Below are instructions for how to download the cell2cell dataset directly from kaggle using the kaggle api. However, this requires authentication, so for simplicity, we have also uploaded the dataset to an Azure hosting and download it from there for convenience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Mev9RwGLzUY"
      },
      "source": [
        "## Download dataset directly from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtnRdsXQTkhd"
      },
      "source": [
        "# ! pip install kaggle --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEmu2ircafkg"
      },
      "source": [
        "Kaggle requires an authentication token for approval to download. After making a Kaggle account, see [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api#authentication) for how to download the kaggle.json file with your username and authentication key. This file should be placed at `~/.kaggle/kaggle.json`, or alternatively the username and key can be passed as environment variables using the commands below. These can be found in the json file.\n",
        "\n",
        "```bash\n",
        "export KAGGLE_USERNAME=user\n",
        "export KAGGLE_KEY=xxxxxxxxxxxxxx\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLtMFMAYcYUa"
      },
      "source": [
        "The command below will download the Telecom Churn dataset from Teradata center for customer relationship management at Duke University from its hosting on Kaggle. See the dataset at the link below:\n",
        "\n",
        "[Kaggle: telecom churn- new cell2cell dataset](https://www.kaggle.com/jpacse/telecom-churn-new-cell2cell-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baeco5teaSzu"
      },
      "source": [
        "# ! kaggle datasets download -d jpacse/telecom-churn-new-cell2cell-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeKlB_43HGuj"
      },
      "source": [
        "## Download dataset from Azure hosting\n",
        "\n",
        "We have temporarily uploaded the dataset to Microsoft Azure for easier download without authentication. The command below will download it into colab directly. The dataset will be hosted on Azure for the duration of the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9_7T5fEHRTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf1680b-395c-420d-fb47-8504be75f99c"
      },
      "source": [
        "%%bash\n",
        "# Only download dataset if it hasn't been done already\n",
        "if [ ! -f \"cell2cell-duke univeristy.csv\" ]; then\n",
        "    wget \"https://syde675gr11.blob.core.windows.net/cell2cell/cell2cell-duke%20univeristy.csv\"\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-22 23:19:35--  https://syde675gr11.blob.core.windows.net/cell2cell/cell2cell-duke%20univeristy.csv\n",
            "Resolving syde675gr11.blob.core.windows.net (syde675gr11.blob.core.windows.net)... 52.239.190.36\n",
            "Connecting to syde675gr11.blob.core.windows.net (syde675gr11.blob.core.windows.net)|52.239.190.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19744061 (19M) [application/vnd.ms-excel]\n",
            "Saving to: ‘cell2cell-duke univeristy.csv’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0%  361K 53s\n",
            "    50K .......... .......... .......... .......... ..........  0%  721K 40s\n",
            "   100K .......... .......... .......... .......... ..........  0%  722K 35s\n",
            "   150K .......... .......... .......... .......... ..........  1%  228M 26s\n",
            "   200K .......... .......... .......... .......... ..........  1%  723K 26s\n",
            "   250K .......... .......... .......... .......... ..........  1%  267M 22s\n",
            "   300K .......... .......... .......... .......... ..........  1%  724K 22s\n",
            "   350K .......... .......... .......... .......... ..........  2%  211M 20s\n",
            "   400K .......... .......... .......... .......... ..........  2%  724K 20s\n",
            "   450K .......... .......... .......... .......... ..........  2%  251M 18s\n",
            "   500K .......... .......... .......... .......... ..........  2%  270M 17s\n",
            "   550K .......... .......... .......... .......... ..........  3%  727K 17s\n",
            "   600K .......... .......... .......... .......... ..........  3%  185M 16s\n",
            "   650K .......... .......... .......... .......... ..........  3%  265M 15s\n",
            "   700K .......... .......... .......... .......... ..........  3%  265M 14s\n",
            "   750K .......... .......... .......... .......... ..........  4%  728K 14s\n",
            "   800K .......... .......... .......... .......... ..........  4%  167M 14s\n",
            "   850K .......... .......... .......... .......... ..........  4%  202M 13s\n",
            "   900K .......... .......... .......... .......... ..........  4%  269M 12s\n",
            "   950K .......... .......... .......... .......... ..........  5%  235M 11s\n",
            "  1000K .......... .......... .......... .......... ..........  5%  728K 12s\n",
            "  1050K .......... .......... .......... .......... ..........  5%  207M 11s\n",
            "  1100K .......... .......... .......... .......... ..........  5%  177M 11s\n",
            "  1150K .......... .......... .......... .......... ..........  6%  199M 10s\n",
            "  1200K .......... .......... .......... .......... ..........  6%  257M 10s\n",
            "  1250K .......... .......... .......... .......... ..........  6%  279M 10s\n",
            "  1300K .......... .......... .......... .......... ..........  7%  735K 10s\n",
            "  1350K .......... .......... .......... .......... ..........  7%  144M 10s\n",
            "  1400K .......... .......... .......... .......... ..........  7%  195M 9s\n",
            "  1450K .......... .......... .......... .......... ..........  7%  236M 9s\n",
            "  1500K .......... .......... .......... .......... ..........  8%  274M 9s\n",
            "  1550K .......... .......... .......... .......... ..........  8%  222M 8s\n",
            "  1600K .......... .......... .......... .......... ..........  8%  279M 8s\n",
            "  1650K .......... .......... .......... .......... ..........  8%  280M 8s\n",
            "  1700K .......... .......... .......... .......... ..........  9%  734K 8s\n",
            "  1750K .......... .......... .......... .......... ..........  9%  149M 8s\n",
            "  1800K .......... .......... .......... .......... ..........  9%  202M 8s\n",
            "  1850K .......... .......... .......... .......... ..........  9%  265M 8s\n",
            "  1900K .......... .......... .......... .......... .......... 10%  267M 7s\n",
            "  1950K .......... .......... .......... .......... .......... 10%  219M 7s\n",
            "  2000K .......... .......... .......... .......... .......... 10%  264M 7s\n",
            "  2050K .......... .......... .......... .......... .......... 10%  261M 7s\n",
            "  2100K .......... .......... .......... .......... .......... 11%  270M 7s\n",
            "  2150K .......... .......... .......... .......... .......... 11%  738K 7s\n",
            "  2200K .......... .......... .......... .......... .......... 11%  175M 7s\n",
            "  2250K .......... .......... .......... .......... .......... 11%  244M 7s\n",
            "  2300K .......... .......... .......... .......... .......... 12%  246M 6s\n",
            "  2350K .......... .......... .......... .......... .......... 12%  222M 6s\n",
            "  2400K .......... .......... .......... .......... .......... 12%  254M 6s\n",
            "  2450K .......... .......... .......... .......... .......... 12%  273M 6s\n",
            "  2500K .......... .......... .......... .......... .......... 13%  267M 6s\n",
            "  2550K .......... .......... .......... .......... .......... 13%  229M 6s\n",
            "  2600K .......... .......... .......... .......... .......... 13%  282M 6s\n",
            "  2650K .......... .......... .......... .......... .......... 14%  268M 6s\n",
            "  2700K .......... .......... .......... .......... .......... 14%  271M 5s\n",
            "  2750K .......... .......... .......... .......... .......... 14%  743K 6s\n",
            "  2800K .......... .......... .......... .......... .......... 14%  237M 6s\n",
            "  2850K .......... .......... .......... .......... .......... 15%  162M 5s\n",
            "  2900K .......... .......... .......... .......... .......... 15%  258M 5s\n",
            "  2950K .......... .......... .......... .......... .......... 15%  249M 5s\n",
            "  3000K .......... .......... .......... .......... .......... 15%  283M 5s\n",
            "  3050K .......... .......... .......... .......... .......... 16%  266M 5s\n",
            "  3100K .......... .......... .......... .......... .......... 16%  283M 5s\n",
            "  3150K .......... .......... .......... .......... .......... 16%  206M 5s\n",
            "  3200K .......... .......... .......... .......... .......... 16%  278M 5s\n",
            "  3250K .......... .......... .......... .......... .......... 17%  285M 5s\n",
            "  3300K .......... .......... .......... .......... .......... 17%  254M 5s\n",
            "  3350K .......... .......... .......... .......... .......... 17%  249M 5s\n",
            "  3400K .......... .......... .......... .......... .......... 17%  748K 5s\n",
            "  3450K .......... .......... .......... .......... .......... 18%  156M 5s\n",
            "  3500K .......... .......... .......... .......... .......... 18%  193M 5s\n",
            "  3550K .......... .......... .......... .......... .......... 18%  235M 5s\n",
            "  3600K .......... .......... .......... .......... .......... 18%  260M 4s\n",
            "  3650K .......... .......... .......... .......... .......... 19%  278M 4s\n",
            "  3700K .......... .......... .......... .......... .......... 19%  266M 4s\n",
            "  3750K .......... .......... .......... .......... .......... 19%  252M 4s\n",
            "  3800K .......... .......... .......... .......... .......... 19%  265M 4s\n",
            "  3850K .......... .......... .......... .......... .......... 20%  272M 4s\n",
            "  3900K .......... .......... .......... .......... .......... 20%  274M 4s\n",
            "  3950K .......... .......... .......... .......... .......... 20%  224M 4s\n",
            "  4000K .......... .......... .......... .......... .......... 21%  287M 4s\n",
            "  4050K .......... .......... .......... .......... .......... 21%  503K 4s\n",
            "  4100K .......... .......... .......... .......... .......... 21% 88.8M 4s\n",
            "  4150K .......... .......... .......... .......... .......... 21%  215M 4s\n",
            "  4200K .......... .......... .......... .......... .......... 22%  138M 4s\n",
            "  4250K .......... .......... .......... .......... .......... 22%  337M 4s\n",
            "  4300K .......... .......... .......... .......... .......... 22%  166M 4s\n",
            "  4350K .......... .......... .......... .......... .......... 22%  297M 4s\n",
            "  4400K .......... .......... .......... .......... .......... 23%  238M 4s\n",
            "  4450K .......... .......... .......... .......... .......... 23%  278M 4s\n",
            "  4500K .......... .......... .......... .......... .......... 23%  311M 4s\n",
            "  4550K .......... .......... .......... .......... .......... 23%  122M 4s\n",
            "  4600K .......... .......... .......... .......... .......... 24%  261M 4s\n",
            "  4650K .......... .......... .......... .......... .......... 24%  284M 4s\n",
            "  4700K .......... .......... .......... .......... .......... 24%  302M 4s\n",
            "  4750K .......... .......... .......... .......... .......... 24%  355M 3s\n",
            "  4800K .......... .......... .......... .......... .......... 25%  288M 3s\n",
            "  4850K .......... .......... .......... .......... .......... 25%  342M 3s\n",
            "  4900K .......... .......... .......... .......... .......... 25%  349M 3s\n",
            "  4950K .......... .......... .......... .......... .......... 25%  316M 3s\n",
            "  5000K .......... .......... .......... .......... .......... 26%  764K 3s\n",
            "  5050K .......... .......... .......... .......... .......... 26%  311M 3s\n",
            "  5100K .......... .......... .......... .......... .......... 26%  183M 3s\n",
            "  5150K .......... .......... .......... .......... .......... 26%  178M 3s\n",
            "  5200K .......... .......... .......... .......... .......... 27%  116M 3s\n",
            "  5250K .......... .......... .......... .......... .......... 27%  228M 3s\n",
            "  5300K .......... .......... .......... .......... .......... 27%  276M 3s\n",
            "  5350K .......... .......... .......... .......... .......... 28%  344M 3s\n",
            "  5400K .......... .......... .......... .......... .......... 28%  153M 3s\n",
            "  5450K .......... .......... .......... .......... .......... 28%  311M 3s\n",
            "  5500K .......... .......... .......... .......... .......... 28%  304M 3s\n",
            "  5550K .......... .......... .......... .......... .......... 29%  309M 3s\n",
            "  5600K .......... .......... .......... .......... .......... 29%  145M 3s\n",
            "  5650K .......... .......... .......... .......... .......... 29%  298M 3s\n",
            "  5700K .......... .......... .......... .......... .......... 29%  262M 3s\n",
            "  5750K .......... .......... .......... .......... .......... 30%  302M 3s\n",
            "  5800K .......... .......... .......... .......... .......... 30%  355M 3s\n",
            "  5850K .......... .......... .......... .......... .......... 30%  517M 3s\n",
            "  5900K .......... .......... .......... .......... .......... 30%  424M 3s\n",
            "  5950K .......... .......... .......... .......... .......... 31%  513M 3s\n",
            "  6000K .......... .......... .......... .......... .......... 31%  763K 3s\n",
            "  6050K .......... .......... .......... .......... .......... 31%  211M 3s\n",
            "  6100K .......... .......... .......... .......... .......... 31%  152M 3s\n",
            "  6150K .......... .......... .......... .......... .......... 32%  154M 3s\n",
            "  6200K .......... .......... .......... .......... .......... 32%  171M 3s\n",
            "  6250K .......... .......... .......... .......... .......... 32%  186M 3s\n",
            "  6300K .......... .......... .......... .......... .......... 32%  209M 3s\n",
            "  6350K .......... .......... .......... .......... .......... 33%  259M 3s\n",
            "  6400K .......... .......... .......... .......... .......... 33%  260M 3s\n",
            "  6450K .......... .......... .......... .......... .......... 33%  306M 3s\n",
            "  6500K .......... .......... .......... .......... .......... 33%  289M 2s\n",
            "  6550K .......... .......... .......... .......... .......... 34%  263M 2s\n",
            "  6600K .......... .......... .......... .......... .......... 34%  256M 2s\n",
            "  6650K .......... .......... .......... .......... .......... 34%  280M 2s\n",
            "  6700K .......... .......... .......... .......... .......... 35%  305M 2s\n",
            "  6750K .......... .......... .......... .......... .......... 35%  301M 2s\n",
            "  6800K .......... .......... .......... .......... .......... 35%  239M 2s\n",
            "  6850K .......... .......... .......... .......... .......... 35%  293M 2s\n",
            "  6900K .......... .......... .......... .......... .......... 36%  292M 2s\n",
            "  6950K .......... .......... .......... .......... .......... 36%  313M 2s\n",
            "  7000K .......... .......... .......... .......... .......... 36%  249M 2s\n",
            "  7050K .......... .......... .......... .......... .......... 36%  290M 2s\n",
            "  7100K .......... .......... .......... .......... .......... 37%  298M 2s\n",
            "  7150K .......... .......... .......... .......... .......... 37%  310M 2s\n",
            "  7200K .......... .......... .......... .......... .......... 37%  771K 2s\n",
            "  7250K .......... .......... .......... .......... .......... 37%  179M 2s\n",
            "  7300K .......... .......... .......... .......... .......... 38%  191M 2s\n",
            "  7350K .......... .......... .......... .......... .......... 38%  198M 2s\n",
            "  7400K .......... .......... .......... .......... .......... 38%  181M 2s\n",
            "  7450K .......... .......... .......... .......... .......... 38% 39.5M 2s\n",
            "  7500K .......... .......... .......... .......... .......... 39%  158M 2s\n",
            "  7550K .......... .......... .......... .......... .......... 39%  172M 2s\n",
            "  7600K .......... .......... .......... .......... .......... 39%  127M 2s\n",
            "  7650K .......... .......... .......... .......... .......... 39%  262M 2s\n",
            "  7700K .......... .......... .......... .......... .......... 40%  379M 2s\n",
            "  7750K .......... .......... .......... .......... .......... 40%  473M 2s\n",
            "  7800K .......... .......... .......... .......... .......... 40%  415M 2s\n",
            "  7850K .......... .......... .......... .......... .......... 40%  362M 2s\n",
            "  7900K .......... .......... .......... .......... .......... 41%  466M 2s\n",
            "  7950K .......... .......... .......... .......... .......... 41%  446M 2s\n",
            "  8000K .......... .......... .......... .......... .......... 41%  386M 2s\n",
            "  8050K .......... .......... .......... .......... .......... 42%  469M 2s\n",
            "  8100K .......... .......... .......... .......... .......... 42%  392M 2s\n",
            "  8150K .......... .......... .......... .......... .......... 42%  508K 2s\n",
            "  8200K .......... .......... .......... .......... .......... 42%  161M 2s\n",
            "  8250K .......... .......... .......... .......... .......... 43%  199M 2s\n",
            "  8300K .......... .......... .......... .......... .......... 43%  204M 2s\n",
            "  8350K .......... .......... .......... .......... .......... 43% 81.1M 2s\n",
            "  8400K .......... .......... .......... .......... .......... 43%  153M 2s\n",
            "  8450K .......... .......... .......... .......... .......... 44%  273M 2s\n",
            "  8500K .......... .......... .......... .......... .......... 44%  280M 2s\n",
            "  8550K .......... .......... .......... .......... .......... 44%  306M 2s\n",
            "  8600K .......... .......... .......... .......... .......... 44%  258M 2s\n",
            "  8650K .......... .......... .......... .......... .......... 45%  306M 2s\n",
            "  8700K .......... .......... .......... .......... .......... 45%  306M 2s\n",
            "  8750K .......... .......... .......... .......... .......... 45%  287M 2s\n",
            "  8800K .......... .......... .......... .......... .......... 45%  246M 2s\n",
            "  8850K .......... .......... .......... .......... .......... 46%  306M 2s\n",
            "  8900K .......... .......... .......... .......... .......... 46%  296M 2s\n",
            "  8950K .......... .......... .......... .......... .......... 46%  306M 2s\n",
            "  9000K .......... .......... .......... .......... .......... 46%  270M 2s\n",
            "  9050K .......... .......... .......... .......... .......... 47%  314M 2s\n",
            "  9100K .......... .......... .......... .......... .......... 47%  289M 2s\n",
            "  9150K .......... .......... .......... .......... .......... 47%  385M 2s\n",
            "  9200K .......... .......... .......... .......... .......... 47%  333M 2s\n",
            "  9250K .......... .......... .......... .......... .......... 48%  527M 2s\n",
            "  9300K .......... .......... .......... .......... .......... 48%  533M 2s\n",
            "  9350K .......... .......... .......... .......... .......... 48%  526M 2s\n",
            "  9400K .......... .......... .......... .......... .......... 49%  476M 2s\n",
            "  9450K .......... .......... .......... .......... .......... 49%  530M 2s\n",
            "  9500K .......... .......... .......... .......... .......... 49%  539M 1s\n",
            "  9550K .......... .......... .......... .......... .......... 49%  415M 1s\n",
            "  9600K .......... .......... .......... .......... .......... 50%  427M 1s\n",
            "  9650K .......... .......... .......... .......... .......... 50%  542M 1s\n",
            "  9700K .......... .......... .......... .......... .......... 50%  503M 1s\n",
            "  9750K .......... .......... .......... .......... .......... 50%  525M 1s\n",
            "  9800K .......... .......... .......... .......... .......... 51%  470M 1s\n",
            "  9850K .......... .......... .......... .......... .......... 51%  525M 1s\n",
            "  9900K .......... .......... .......... .......... .......... 51%  782K 1s\n",
            "  9950K .......... .......... .......... .......... .......... 51%  205M 1s\n",
            " 10000K .......... .......... .......... .......... .......... 52%  138M 1s\n",
            " 10050K .......... .......... .......... .......... .......... 52%  197M 1s\n",
            " 10100K .......... .......... .......... .......... .......... 52%  159M 1s\n",
            " 10150K .......... .......... .......... .......... .......... 52%  176M 1s\n",
            " 10200K .......... .......... .......... .......... .......... 53%  105M 1s\n",
            " 10250K .......... .......... .......... .......... .......... 53%  307M 1s\n",
            " 10300K .......... .......... .......... .......... .......... 53%  303M 1s\n",
            " 10350K .......... .......... .......... .......... .......... 53%  277M 1s\n",
            " 10400K .......... .......... .......... .......... .......... 54%  224M 1s\n",
            " 10450K .......... .......... .......... .......... .......... 54%  279M 1s\n",
            " 10500K .......... .......... .......... .......... .......... 54%  282M 1s\n",
            " 10550K .......... .......... .......... .......... .......... 54%  293M 1s\n",
            " 10600K .......... .......... .......... .......... .......... 55%  283M 1s\n",
            " 10650K .......... .......... .......... .......... .......... 55%  295M 1s\n",
            " 10700K .......... .......... .......... .......... .......... 55%  308M 1s\n",
            " 10750K .......... .......... .......... .......... .......... 56%  279M 1s\n",
            " 10800K .......... .......... .......... .......... .......... 56%  252M 1s\n",
            " 10850K .......... .......... .......... .......... .......... 56%  293M 1s\n",
            " 10900K .......... .......... .......... .......... .......... 56%  289M 1s\n",
            " 10950K .......... .......... .......... .......... .......... 57%  294M 1s\n",
            " 11000K .......... .......... .......... .......... .......... 57%  269M 1s\n",
            " 11050K .......... .......... .......... .......... .......... 57%  269M 1s\n",
            " 11100K .......... .......... .......... .......... .......... 57%  300M 1s\n",
            " 11150K .......... .......... .......... .......... .......... 58%  280M 1s\n",
            " 11200K .......... .......... .......... .......... .......... 58%  249M 1s\n",
            " 11250K .......... .......... .......... .......... .......... 58%  247M 1s\n",
            " 11300K .......... .......... .......... .......... .......... 58%  260M 1s\n",
            " 11350K .......... .......... .......... .......... .......... 59%  268M 1s\n",
            " 11400K .......... .......... .......... .......... .......... 59%  213M 1s\n",
            " 11450K .......... .......... .......... .......... .......... 59%  276M 1s\n",
            " 11500K .......... .......... .......... .......... .......... 59%  239M 1s\n",
            " 11550K .......... .......... .......... .......... .......... 60%  262M 1s\n",
            " 11600K .......... .......... .......... .......... .......... 60%  235M 1s\n",
            " 11650K .......... .......... .......... .......... .......... 60%  245M 1s\n",
            " 11700K .......... .......... .......... .......... .......... 60%  277M 1s\n",
            " 11750K .......... .......... .......... .......... .......... 61%  291M 1s\n",
            " 11800K .......... .......... .......... .......... .......... 61%  277M 1s\n",
            " 11850K .......... .......... .......... .......... .......... 61%  809K 1s\n",
            " 11900K .......... .......... .......... .......... .......... 61%  221M 1s\n",
            " 11950K .......... .......... .......... .......... .......... 62%  310M 1s\n",
            " 12000K .......... .......... .......... .......... .......... 62%  261M 1s\n",
            " 12050K .......... .......... .......... .......... .......... 62%  309M 1s\n",
            " 12100K .......... .......... .......... .......... .......... 63%  266M 1s\n",
            " 12150K .......... .......... .......... .......... .......... 63%  296M 1s\n",
            " 12200K .......... .......... .......... .......... .......... 63%  272M 1s\n",
            " 12250K .......... .......... .......... .......... .......... 63%  516K 1s\n",
            " 12300K .......... .......... .......... .......... .......... 64%  195M 1s\n",
            " 12350K .......... .......... .......... .......... .......... 64%  187M 1s\n",
            " 12400K .......... .......... .......... .......... .......... 64%  177M 1s\n",
            " 12450K .......... .......... .......... .......... .......... 64%  196M 1s\n",
            " 12500K .......... .......... .......... .......... .......... 65%  184M 1s\n",
            " 12550K .......... .......... .......... .......... .......... 65%  201M 1s\n",
            " 12600K .......... .......... .......... .......... .......... 65%  177M 1s\n",
            " 12650K .......... .......... .......... .......... .......... 65%  198M 1s\n",
            " 12700K .......... .......... .......... .......... .......... 66%  267M 1s\n",
            " 12750K .......... .......... .......... .......... .......... 66%  327M 1s\n",
            " 12800K .......... .......... .......... .......... .......... 66%  265M 1s\n",
            " 12850K .......... .......... .......... .......... .......... 66%  315M 1s\n",
            " 12900K .......... .......... .......... .......... .......... 67%  272M 1s\n",
            " 12950K .......... .......... .......... .......... .......... 67%  308M 1s\n",
            " 13000K .......... .......... .......... .......... .......... 67%  262M 1s\n",
            " 13050K .......... .......... .......... .......... .......... 67%  314M 1s\n",
            " 13100K .......... .......... .......... .......... .......... 68%  314M 1s\n",
            " 13150K .......... .......... .......... .......... .......... 68%  326M 1s\n",
            " 13200K .......... .......... .......... .......... .......... 68%  253M 1s\n",
            " 13250K .......... .......... .......... .......... .......... 68%  316M 1s\n",
            " 13300K .......... .......... .......... .......... .......... 69%  258M 1s\n",
            " 13350K .......... .......... .......... .......... .......... 69%  296M 1s\n",
            " 13400K .......... .......... .......... .......... .......... 69%  284M 1s\n",
            " 13450K .......... .......... .......... .......... .......... 70%  317M 1s\n",
            " 13500K .......... .......... .......... .......... .......... 70%  295M 1s\n",
            " 13550K .......... .......... .......... .......... .......... 70%  293M 1s\n",
            " 13600K .......... .......... .......... .......... .......... 70%  256M 1s\n",
            " 13650K .......... .......... .......... .......... .......... 71%  313M 1s\n",
            " 13700K .......... .......... .......... .......... .......... 71%  307M 1s\n",
            " 13750K .......... .......... .......... .......... .......... 71%  304M 1s\n",
            " 13800K .......... .......... .......... .......... .......... 71%  261M 1s\n",
            " 13850K .......... .......... .......... .......... .......... 72%  322M 1s\n",
            " 13900K .......... .......... .......... .......... .......... 72%  297M 1s\n",
            " 13950K .......... .......... .......... .......... .......... 72%  301M 1s\n",
            " 14000K .......... .......... .......... .......... .......... 72%  259M 1s\n",
            " 14050K .......... .......... .......... .......... .......... 73%  306M 1s\n",
            " 14100K .......... .......... .......... .......... .......... 73%  294M 1s\n",
            " 14150K .......... .......... .......... .......... .......... 73%  313M 1s\n",
            " 14200K .......... .......... .......... .......... .......... 73%  264M 1s\n",
            " 14250K .......... .......... .......... .......... .......... 74%  318M 1s\n",
            " 14300K .......... .......... .......... .......... .......... 74%  311M 1s\n",
            " 14350K .......... .......... .......... .......... .......... 74%  326M 1s\n",
            " 14400K .......... .......... .......... .......... .......... 74%  249M 1s\n",
            " 14450K .......... .......... .......... .......... .......... 75%  309M 1s\n",
            " 14500K .......... .......... .......... .......... .......... 75%  299M 1s\n",
            " 14550K .......... .......... .......... .......... .......... 75%  819K 1s\n",
            " 14600K .......... .......... .......... .......... .......... 75%  162M 1s\n",
            " 14650K .......... .......... .......... .......... .......... 76%  173M 1s\n",
            " 14700K .......... .......... .......... .......... .......... 76%  169M 1s\n",
            " 14750K .......... .......... .......... .......... .......... 76%  210M 1s\n",
            " 14800K .......... .......... .......... .......... .......... 77%  179M 1s\n",
            " 14850K .......... .......... .......... .......... .......... 77%  178M 1s\n",
            " 14900K .......... .......... .......... .......... .......... 77%  243M 1s\n",
            " 14950K .......... .......... .......... .......... .......... 77%  303M 1s\n",
            " 15000K .......... .......... .......... .......... .......... 78%  270M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 78%  315M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 78%  301M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 78%  311M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 79%  193M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 79%  247M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 79%  260M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 79%  267M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 80%  222M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 80%  257M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 80%  275M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 80%  253M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 81%  228M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 81%  262M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 81%  316M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 81%  302M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 82%  266M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 82%  317M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 82%  319M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 82%  298M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 83%  263M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 83%  295M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 83%  315M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 84%  312M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 84%  271M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 84%  294M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 84%  314M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 85%  676K 0s\n",
            " 16400K .......... .......... .......... .......... .......... 85%  144M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 85%  197M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 85%  199M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 86%  188M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 86%  183M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 86%  191M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 86%  184M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 87%  235M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 87%  252M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 87%  306M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 87%  306M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 88%  287M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 88%  268M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 88%  288M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 88%  300M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 89%  310M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 89%  259M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 89%  284M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 89%  314M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 90%  277M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 90%  272M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 90%  317M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 91%  311M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 91%  295M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 91%  256M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 91%  293M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 92%  306M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 92%  306M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 92%  276M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 92%  284M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 93%  316M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 93%  302M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 93%  261M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 93%  297M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 94%  304M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 94%  285M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 94%  277M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 94%  277M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 95%  306M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 95%  312M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 95%  268M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 95%  291M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 96%  313M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 96%  815K 0s\n",
            " 18600K .......... .......... .......... .......... .......... 96%  138M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 96%  170M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 97%  260M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 97%  264M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 97%  234M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 98%  308M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 98%  275M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 98%  251M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 98%  270M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 99%  303M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 99%  312M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 99%  284M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 99%  137M 0s\n",
            " 19250K .......... .......... .......... .                    100%  270M=1.9s\n",
            "\n",
            "2021-04-22 23:19:37 (9.85 MB/s) - ‘cell2cell-duke univeristy.csv’ saved [19744061/19744061]\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWzj1fX1Kdc3"
      },
      "source": [
        "# Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPElvl2bITko",
        "outputId": "99cd33c6-08ff-4224-b953-4fb496b292c9"
      },
      "source": [
        "# Import the dataset\n",
        "data = pd.read_csv('cell2cell-duke univeristy.csv')\n",
        "# Print number of churn/no-churn in original dataset\n",
        "print('Dataset Length:\\t{}'.format(data.shape[0]))\n",
        "print('# of Churn:    \\t{}'.format(sum(data['churn'] == 1)))\n",
        "print('# of Non-Churn:\\t{}'.format(sum(data['churn'] == 0)))\n",
        "\n",
        "cols_with_null = []\n",
        "\n",
        "for column in data:\n",
        "    # Find columns that have null or missing values\n",
        "    if data[column].isnull().any():\n",
        "        cols_with_null.append(column)\n",
        "        \n",
        "print('cols_with_null ({}): {}'.format(len(cols_with_null), cols_with_null))\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Length:\t71047\n",
            "# of Churn:    \t20609\n",
            "# of Non-Churn:\t50438\n",
            "cols_with_null (14): ['churndep', 'revenue', 'mou', 'recchrge', 'directas', 'overage', 'roam', 'changem', 'changer', 'phones', 'models', 'eqpdays', 'age1', 'age2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMrCDiajKftJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64585b02-c5b9-4edb-e3aa-d121ba49a9d3"
      },
      "source": [
        "# The following columns will be dropped as they provide no useful information\n",
        "# The first two columns ('Unnamed: 0' and 'X') are simply the row index\n",
        "# The 'customer' column contains a unique customer ID\n",
        "# The 'traintest' column is whether the row is part of the training set. We will make our own\n",
        "# train/test splits.\n",
        "# The 'churndep' column is a duplicate of the churn column where it has null values\n",
        "# for the testset rows\n",
        "df = data.drop(columns=['Unnamed: 0','X','customer','traintest','churndep'])\n",
        "\n",
        "# Count number of null values in each row\n",
        "count = collections.Counter(df.isnull().sum(axis=1))\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 69309, 2: 1518, 8: 210, 10: 6, 4: 3, 3: 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ49WpB5MW1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d24b66-a169-4dc8-947f-b3f8d69d1e91"
      },
      "source": [
        "# Remove all rows that have null for more than 7 variables\n",
        "df = df.dropna(axis=0, thresh=df.shape[1]-7)\n",
        "\n",
        "# split into X and y variables\n",
        "X, y = df.drop(columns='churn'), df['churn']\n",
        "print('X shape', X.shape)\n",
        "print('y shape', y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape (70831, 66)\n",
            "y shape (70831,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du_kmAHKMZCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a238a778-ada9-40f9-9867-e401ecb9da71"
      },
      "source": [
        "# Show features that still contain NA values\n",
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "churn          0\n",
              "revenue        0\n",
              "mou            0\n",
              "recchrge       0\n",
              "directas       0\n",
              "overage        0\n",
              "roam           0\n",
              "changem      286\n",
              "changer      286\n",
              "dropvce        0\n",
              "blckvce        0\n",
              "unansvce       0\n",
              "custcare       0\n",
              "threeway       0\n",
              "mourec         0\n",
              "outcalls       0\n",
              "incalls        0\n",
              "peakvce        0\n",
              "opeakvce       0\n",
              "dropblk        0\n",
              "callfwdv       0\n",
              "callwait       0\n",
              "months         0\n",
              "uniqsubs       0\n",
              "actvsubs       0\n",
              "phones         1\n",
              "models         1\n",
              "eqpdays        1\n",
              "age1        1238\n",
              "age2        1238\n",
              "children       0\n",
              "credita        0\n",
              "creditaa       0\n",
              "prizmrur       0\n",
              "prizmub        0\n",
              "prizmtwn       0\n",
              "refurb         0\n",
              "webcap         0\n",
              "truck          0\n",
              "rv             0\n",
              "occprof        0\n",
              "occcler        0\n",
              "occcrft        0\n",
              "occstud        0\n",
              "occhmkr        0\n",
              "occret         0\n",
              "occself        0\n",
              "ownrent        0\n",
              "marryun        0\n",
              "marryyes       0\n",
              "mailord        0\n",
              "mailres        0\n",
              "mailflag       0\n",
              "travel         0\n",
              "pcown          0\n",
              "creditcd       0\n",
              "retcalls       0\n",
              "retaccpt       0\n",
              "newcelly       0\n",
              "newcelln       0\n",
              "refer          0\n",
              "incmiss        0\n",
              "income         0\n",
              "mcycle         0\n",
              "setprcm        0\n",
              "setprc         0\n",
              "retcall        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24nyy5YVMiUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07439a5b-9c59-416f-dc07-a821b1afd888"
      },
      "source": [
        "# Find columns that still contain null values\n",
        "cols_with_null = []\n",
        "\n",
        "for column in X:\n",
        "    # Find columns that have null or missing values\n",
        "    if X[column].isnull().any():\n",
        "        cols_with_null.append(column)\n",
        "        \n",
        "print('cols_with_null ({}): {}'.format(len(cols_with_null), cols_with_null))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cols_with_null (7): ['changem', 'changer', 'phones', 'models', 'eqpdays', 'age1', 'age2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TvIacTcMmr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22a9665-b68f-472e-bfb3-dd2ec4ab2b21"
      },
      "source": [
        "# Use simple imputer to convert null values to 0\n",
        "# Note that this will return an ndarray, not a pandas dataframe\n",
        "# imp_const = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
        "# X = imp_const.fit_transform(X)\n",
        "\n",
        "# Convert all null values to 0 using pandas\n",
        "X = X.fillna(0)\n",
        "\n",
        "# Count number of null values in each row\n",
        "count = collections.Counter(X.isnull().sum(axis=1))\n",
        "print(count)\n",
        "\n",
        "X.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 70831})\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 70831 entries, 0 to 71042\n",
            "Data columns (total 66 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   revenue   70831 non-null  float64\n",
            " 1   mou       70831 non-null  float64\n",
            " 2   recchrge  70831 non-null  float64\n",
            " 3   directas  70831 non-null  float64\n",
            " 4   overage   70831 non-null  float64\n",
            " 5   roam      70831 non-null  float64\n",
            " 6   changem   70831 non-null  float64\n",
            " 7   changer   70831 non-null  float64\n",
            " 8   dropvce   70831 non-null  float64\n",
            " 9   blckvce   70831 non-null  float64\n",
            " 10  unansvce  70831 non-null  float64\n",
            " 11  custcare  70831 non-null  float64\n",
            " 12  threeway  70831 non-null  float64\n",
            " 13  mourec    70831 non-null  float64\n",
            " 14  outcalls  70831 non-null  float64\n",
            " 15  incalls   70831 non-null  float64\n",
            " 16  peakvce   70831 non-null  float64\n",
            " 17  opeakvce  70831 non-null  float64\n",
            " 18  dropblk   70831 non-null  float64\n",
            " 19  callfwdv  70831 non-null  float64\n",
            " 20  callwait  70831 non-null  float64\n",
            " 21  months    70831 non-null  int64  \n",
            " 22  uniqsubs  70831 non-null  int64  \n",
            " 23  actvsubs  70831 non-null  int64  \n",
            " 24  phones    70831 non-null  float64\n",
            " 25  models    70831 non-null  float64\n",
            " 26  eqpdays   70831 non-null  float64\n",
            " 27  age1      70831 non-null  float64\n",
            " 28  age2      70831 non-null  float64\n",
            " 29  children  70831 non-null  int64  \n",
            " 30  credita   70831 non-null  int64  \n",
            " 31  creditaa  70831 non-null  int64  \n",
            " 32  prizmrur  70831 non-null  int64  \n",
            " 33  prizmub   70831 non-null  int64  \n",
            " 34  prizmtwn  70831 non-null  int64  \n",
            " 35  refurb    70831 non-null  int64  \n",
            " 36  webcap    70831 non-null  int64  \n",
            " 37  truck     70831 non-null  int64  \n",
            " 38  rv        70831 non-null  int64  \n",
            " 39  occprof   70831 non-null  int64  \n",
            " 40  occcler   70831 non-null  int64  \n",
            " 41  occcrft   70831 non-null  int64  \n",
            " 42  occstud   70831 non-null  int64  \n",
            " 43  occhmkr   70831 non-null  int64  \n",
            " 44  occret    70831 non-null  int64  \n",
            " 45  occself   70831 non-null  int64  \n",
            " 46  ownrent   70831 non-null  int64  \n",
            " 47  marryun   70831 non-null  int64  \n",
            " 48  marryyes  70831 non-null  int64  \n",
            " 49  mailord   70831 non-null  int64  \n",
            " 50  mailres   70831 non-null  int64  \n",
            " 51  mailflag  70831 non-null  int64  \n",
            " 52  travel    70831 non-null  int64  \n",
            " 53  pcown     70831 non-null  int64  \n",
            " 54  creditcd  70831 non-null  int64  \n",
            " 55  retcalls  70831 non-null  int64  \n",
            " 56  retaccpt  70831 non-null  int64  \n",
            " 57  newcelly  70831 non-null  int64  \n",
            " 58  newcelln  70831 non-null  int64  \n",
            " 59  refer     70831 non-null  int64  \n",
            " 60  incmiss   70831 non-null  int64  \n",
            " 61  income    70831 non-null  int64  \n",
            " 62  mcycle    70831 non-null  int64  \n",
            " 63  setprcm   70831 non-null  int64  \n",
            " 64  setprc    70831 non-null  float64\n",
            " 65  retcall   70831 non-null  int64  \n",
            "dtypes: float64(27), int64(39)\n",
            "memory usage: 36.2 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v847O1fMqF-"
      },
      "source": [
        "## Standardize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUSO_wotMow3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5036592-df98-4cc7-9577-389387d3df98"
      },
      "source": [
        "def baseline_model_acc(X, y):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "    lr = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
        "    # rf = RandomForestClassifier(n_estimators=500, class_weight='balanced')\n",
        "    y_pred = lr.predict(X_val)\n",
        "    y_pred_prob = lr.predict_proba(X_val)[:,1]\n",
        "    print(np.unique(y_val, return_counts=True), np.unique(y_pred, return_counts=True))\n",
        "    print('acc:', metrics.accuracy_score(y_true=y_val, y_pred=y_pred))\n",
        "    print('roc auc:', metrics.roc_auc_score(y_val, y_pred_prob))\n",
        "    print('precision, recall, fscore:', metrics.precision_recall_fscore_support(y_val, y_pred))\n",
        "\n",
        "    y_pred_train = lr.predict(X_train)\n",
        "    print('Training acc:', metrics.accuracy_score(y_true=y_train, y_pred=y_pred_train))\n",
        "    return metrics.roc_auc_score(y_val, y_pred_prob)\n",
        "\n",
        "# Find non-binary columns\n",
        "non_binary = []\n",
        "\n",
        "for column in X:\n",
        "    if len(X[column].unique()) > 2:\n",
        "        non_binary.append(column)\n",
        "        \n",
        "print('non_binary ({}): {}'.format(len(non_binary), non_binary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "non_binary (34): ['revenue', 'mou', 'recchrge', 'directas', 'overage', 'roam', 'changem', 'changer', 'dropvce', 'blckvce', 'unansvce', 'custcare', 'threeway', 'mourec', 'outcalls', 'incalls', 'peakvce', 'opeakvce', 'dropblk', 'callfwdv', 'callwait', 'months', 'uniqsubs', 'actvsubs', 'phones', 'models', 'eqpdays', 'age1', 'age2', 'retcalls', 'retaccpt', 'refer', 'income', 'setprc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbYUZx1jMvqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c136e0-b8d2-43c2-8ff8-85665ea889c1"
      },
      "source": [
        "# Logistic performance before standardization\n",
        "auc0 = baseline_model_acc(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([10035,  4132])) (array([0, 1]), array([14022,   145]))\n",
            "acc: 0.7071363026752312\n",
            "roc auc: 0.6168600122224682\n",
            "precision, recall, fscore: (array([0.70988447, 0.44137931]), array([0.99192825, 0.01548887]), array([0.82753461, 0.02992752]), array([10035,  4132]))\n",
            "Training acc: 0.7110864040660737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut7fenruNhCP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7356e89-3d84-465a-e0b9-d5d31a6ac0dc"
      },
      "source": [
        "# Test performance with mean and variance standardization\n",
        "non_binary_feats = X[non_binary]\n",
        "scalar = StandardScaler(with_mean=True,with_std=True)\n",
        "standard_feats = scalar.fit_transform(non_binary_feats.values)\n",
        "X1 = X.copy()\n",
        "X1[non_binary] = standard_feats\n",
        "\n",
        "# Logistic performance with zero mean and variance standardization\n",
        "auc1 = baseline_model_acc(X1,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([10035,  4132])) (array([0, 1]), array([13867,   300]))\n",
            "acc: 0.7086186207383356\n",
            "roc auc: 0.6213706287432514\n",
            "precision, recall, fscore: (array([0.71298767, 0.50666667]), array([0.98525162, 0.03678606]), array([0.82729479, 0.06859206]), array([10035,  4132]))\n",
            "Training acc: 0.7120923337568826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnkHw1ojO0TT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40faecec-b76f-4e4d-d7d4-74497bb29fb5"
      },
      "source": [
        "# Test performance with min max scaler\n",
        "non_binary_feats = X[non_binary]\n",
        "mm_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "min_max_feats = mm_scaler.fit_transform(non_binary_feats.values)\n",
        "X2 = X.copy()\n",
        "X2[non_binary] = min_max_feats\n",
        "\n",
        "# Logistic performance with min max scaler\n",
        "auc2 = baseline_model_acc(X2,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([10035,  4132])) (array([0, 1]), array([13912,   255]))\n",
            "acc: 0.7092538999082375\n",
            "roc auc: 0.61595562674878\n",
            "precision, recall, fscore: (array([0.7126222, 0.5254902]), array([0.9879422 , 0.03242982]), array([0.82799516, 0.06108958]), array([10035,  4132]))\n",
            "Training acc: 0.7116864323026966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69VZ0X-KS38Y"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iapHnjMNi6I"
      },
      "source": [
        "# Make a train test split\n",
        "X = X2\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsJX19gyTvGS"
      },
      "source": [
        "# Dataset Sampling Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X53EsJduBd7"
      },
      "source": [
        "def rf_train_test_split_sampler(sampler, ratio=1.0):\n",
        "  sample = sampler(sampling_strategy=ratio)\n",
        "\n",
        "  X_train_sampled, y_train_sampled = sample.fit_resample(X_train, y_train) \n",
        "  rf = RandomForestClassifier(n_estimators=500, random_state=0, criterion='gini')\n",
        "  rf.fit(X_train_sampled, y_train_sampled)\n",
        "  y_pred = rf.predict(X_val)\n",
        "  y_pred_prob = rf.predict_proba(X_val)[:,1]\n",
        "\n",
        "  print(np.unique(y_val, return_counts=True), np.unique(y_pred, return_counts=True))\n",
        "  print('acc:', metrics.accuracy_score(y_true=y_val, y_pred=y_pred))\n",
        "  print('roc auc:', metrics.roc_auc_score(y_val, y_pred_prob))\n",
        "  print('precision, recall, fscore:', metrics.precision_recall_fscore_support(y_val, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvCSywTzPNjt"
      },
      "source": [
        "def CV_Kfold_5(sampler, sampling, testing_model, X, y, ratio = 1.0):\n",
        "    # Initialize the lists \n",
        "    acc_scores, auc_scores, p_scores, r_scores, f_scores, kf = [], [], [], [], [], 0\n",
        "\n",
        "    # Initialize the Kfolds\n",
        "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Iterate through Kfold indexes \n",
        "    for train_index, test_index in folds.split(X, y):\n",
        "\n",
        "      # Initialize the data based on Kfold index\n",
        "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "      # if sampling apply sampler\n",
        "      if sampling:\n",
        "        X_train, y_train = sampler(sampling_strategy=ratio).fit_resample(X_train, y_train)\n",
        "      \n",
        "      # Set model we are testing to model parameter so it retrains the model new for each Kfold\n",
        "      model = testing_model\n",
        "\n",
        "      print('Fitting')\n",
        " \n",
        "\n",
        "      # Fit model to the data and predict \n",
        "      model.fit(X_train, y_train)\n",
        "\n",
        "      print('Predicting')\n",
        "      \n",
        "\n",
        "      y_pred = model.predict(X_test)\n",
        "      y_pred_prob = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "      print('Obtaining metric')\n",
        "\n",
        "      p_score, r_score, f_score, _ = metrics.precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "      # append metric scores to a list \n",
        "      acc_scores.append(metrics.accuracy_score(y_true=y_test, y_pred=y_pred))\n",
        "      auc_scores.append(metrics.roc_auc_score(y_test, y_pred_prob))\n",
        "      p_scores.append(p_score[1])\n",
        "      r_scores.append(r_score[1])\n",
        "      f_scores.append(f_score[1])\n",
        "\n",
        "      # Print the fold of each loop\n",
        "      kf += 1\n",
        "      print('KFold ' + str(kf) + ' completed')\n",
        "\n",
        "    # return the metric lists, min, max, and mean \n",
        "    mean_acc = np.mean(acc_scores)\n",
        "    mean_auc = np.mean(auc_scores)\n",
        "    mean_p = np.mean(p_scores)\n",
        "    mean_r = np.mean(r_scores)\n",
        "    mean_f = np.mean(f_scores)\n",
        "\n",
        "    min_acc = np.min(acc_scores)\n",
        "    min_auc = np.min(auc_scores)\n",
        "    min_p = np.min(p_scores)\n",
        "    min_r = np.min(r_scores)\n",
        "    min_f = np.min(f_scores)\n",
        "\n",
        "    max_acc = np.max(acc_scores)\n",
        "    max_auc = np.max(auc_scores)\n",
        "    max_p = np.max(p_scores)\n",
        "    max_r = np.max(r_scores)\n",
        "    max_f = np.max(f_scores)\n",
        "\n",
        "    # Create Dictionaries of the 5 metrics and their min, mean, max\n",
        "    acc = {'Accuracy': acc_scores, 'mean' : mean_acc, 'min' : min_acc, 'max' : max_acc}\n",
        "    auc = {'AUC': auc_scores, 'mean' : mean_auc, 'min' : min_auc, 'max' : max_auc}\n",
        "    precision = {'Precision': p_scores, 'mean' : mean_p, 'min' : min_p, 'max' : max_p}\n",
        "    recall = {'Recall': r_scores, 'mean' : mean_r, 'min' : min_r, 'max' : max_r}\n",
        "    f_score = {'F_score': f_scores, 'mean' : mean_f, 'min' : min_f, 'max' : max_f}\n",
        "\n",
        "    return acc, auc, precision, recall, f_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHCM1DRCT1Lh"
      },
      "source": [
        "## Oversampling with Borderline SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KSHuhgnV_Ig"
      },
      "source": [
        "sampling test with train test split instead of cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnVmyFVqVyrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492786a4-6bdc-48d3-ae1c-48dd09b18cce"
      },
      "source": [
        "oversample = BorderlineSMOTE(sampling_strategy=0.67)\n",
        "X_train_bsmote, y_train_bsmote = oversample.fit_resample(X_train, y_train)\n",
        "rf = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,\n",
        "                                  random_state =0, max_features = \"auto\",\n",
        "                                  max_leaf_nodes = 80)\n",
        "rf.fit(X_train_bsmote, y_train_bsmote)\n",
        "y_pred = rf.predict(X_val)\n",
        "y_pred_prob = rf.predict_proba(X_val)[:,1]\n",
        "print(np.unique(y_val, return_counts=True), np.unique(y_pred, return_counts=True))\n",
        "print('acc:', metrics.accuracy_score(y_true=y_val, y_pred=y_pred))\n",
        "print('roc auc:', metrics.roc_auc_score(y_val, y_pred_prob))\n",
        "print('precision, recall, fscore:', metrics.precision_recall_fscore_support(y_val, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([10035,  4132])) (array([0, 1]), array([13737,   430]))\n",
            "acc: 0.7081951012917344\n",
            "roc auc: 0.6515505749238748\n",
            "precision, recall, fscore: (array([0.71478489, 0.49767442]), array([0.97847534, 0.0517909 ]), array([0.82609793, 0.0938185 ]), array([10035,  4132]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2M8AU5wvB2L"
      },
      "source": [
        "for i in [3/7, 0.67, 1]:\n",
        "  rf_train_test_split_sampler(BorderlineSMOTE, ratio=i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADaBpQWaT8Zu"
      },
      "source": [
        "## Oversampling with SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9b_ZEvZvMdD"
      },
      "source": [
        "for i in [3/7, 0.67, 1.0]:\n",
        "  rf_train_test_split_sampler(SMOTE, ratio=i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7frNScQUFDW"
      },
      "source": [
        "## Random Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib-fNSBTvS6o"
      },
      "source": [
        "for i in [3/7, 0.67, 1.0]:\n",
        "  rf_train_test_split_sampler(RandomOverSampler, ratio=i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7S0SBR3ULgG"
      },
      "source": [
        "## Random Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emz_RvSAvV5c"
      },
      "source": [
        "for i in [3/7, 0.67, 1.0]:\n",
        "  rf_train_test_split_sampler(RandomUnderSampler, ratio=i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1LEStmBSL2W"
      },
      "source": [
        "undersample = RandomUnderSampler(sampling_strategy=1)\n",
        "X_under, y_under = undersample.fit_resample(X, y) \n",
        "X_train_under, X_val_under, y_train_under, y_val_under = train_test_split(X_under, y_under, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNaSZ72PPySk"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLuN_TqBoO0d"
      },
      "source": [
        "## LR Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTsQ9shPP0rV"
      },
      "source": [
        "# Set a parameter dictionary for the GridSearch,\n",
        "params = {'solver': ['newton-cg', 'lbfgs', 'liblinear'], \n",
        "              'C': [0.1, 0.01, 1, 2, 10], \n",
        "              'penalty': ['l1', 'l2', 'elasticnet', 'none'], \n",
        "         }\n",
        "\n",
        "# Call the model function \n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Set GridSearch on a cv = 5\n",
        "lr_cv_model = GridSearchCV(lr, params, cv = 5)\n",
        "\n",
        "# Fit the Gridsearch model to find the opitmal parameters\n",
        "lr_cv_model.fit(X_train, y_train)\n",
        "\n",
        "# Print out the best parameter set \n",
        "print(\"Best Parameters : \",lr_cv_model.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC7PoWcaa0Eb",
        "outputId": "ce4f792a-f079-4e57-cfd0-be314b90876d"
      },
      "source": [
        "lr_cv_model.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.1, 'penalty': 'none', 'solver': 'newton-cg'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Y869oDoVFA"
      },
      "source": [
        "## LR Model No Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykUrN7HMf61n",
        "outputId": "19477a21-f7d5-4d40-a342-a9ba6958b040"
      },
      "source": [
        "# lr no sampler \n",
        "lr = LogisticRegression(random_state=0, solver='newton-cg', penalty='none')\n",
        "\n",
        "lr_base_metrics = CV_Kfold_5(None, None, lr, X, y, ratio = 1.0)\n",
        "# lr.fit(X_train, y_train)\n",
        "# y_pred = lr.predict(X_val)\n",
        "# y_pred_prob = lr.predict_proba(X_val)[:,1]\n",
        "# print(np.unique(y_val, return_counts=True), np.unique(y_pred, return_counts=True))\n",
        "# print('acc:', metrics.accuracy_score(y_true=y_val, y_pred=y_pred))\n",
        "# print('roc auc:', metrics.roc_auc_score(y_val, y_pred_prob))\n",
        "# print('precision, recall, fscore:', metrics.precision_recall_fscore_support(y_val, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 1 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 2 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 3 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 4 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 5 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHwjCmdshY7p",
        "outputId": "d911fc2a-ac00-4677-f4ba-379c997734f1"
      },
      "source": [
        "lr_base_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Accuracy': [0.7117950165878449,\n",
              "   0.710856981505012,\n",
              "   0.7104334321615134,\n",
              "   0.7090921925737682,\n",
              "   0.7122688126500071],\n",
              "  'max': 0.7122688126500071,\n",
              "  'mean': 0.7108892870956292,\n",
              "  'min': 0.7090921925737682},\n",
              " {'AUC': [0.6132724457497852,\n",
              "   0.6124962675552097,\n",
              "   0.6203935090044436,\n",
              "   0.6136105802408705,\n",
              "   0.6150036709692293],\n",
              "  'max': 0.6203935090044436,\n",
              "  'mean': 0.6149552947039076,\n",
              "  'min': 0.6124962675552097},\n",
              " {'Precision': [0.53515625,\n",
              "   0.5092250922509225,\n",
              "   0.4978540772532189,\n",
              "   0.4647887323943662,\n",
              "   0.5550660792951542],\n",
              "  'max': 0.5550660792951542,\n",
              "  'mean': 0.5124180462387323,\n",
              "  'min': 0.4647887323943662},\n",
              " {'Recall': [0.03340648622287247,\n",
              "   0.033650329188002925,\n",
              "   0.028285783955132895,\n",
              "   0.03218727139722019,\n",
              "   0.030724213606437453],\n",
              "  'max': 0.033650329188002925,\n",
              "  'mean': 0.03165081687393319,\n",
              "  'min': 0.028285783955132895},\n",
              " {'F_score': [0.06288730778058298,\n",
              "   0.06312900274473925,\n",
              "   0.05353022611905861,\n",
              "   0.06020524515393387,\n",
              "   0.05822550831792977],\n",
              "  'max': 0.06312900274473925,\n",
              "  'mean': 0.05959545802324889,\n",
              "  'min': 0.05353022611905861})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnROFBWBoXro"
      },
      "source": [
        "## LR Model 1:1 Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODEgUm5VgWzv",
        "outputId": "20c62211-b642-4f01-caf1-72479ac32998"
      },
      "source": [
        "# lr under sampler \n",
        "# lr = LogisticRegression(max_iter=1000, random_state=0)\n",
        "lr = LogisticRegression(random_state=0, solver='newton-cg', penalty='none')\n",
        "\n",
        "lr_under_metrics = CV_Kfold_5(RandomUnderSampler, True, lr, X, y, ratio = 1.0)\n",
        "# lr.fit(X_train, y_train)\n",
        "# y_pred = lr.predict(X_val)\n",
        "# y_pred_prob = lr.predict_proba(X_val)[:,1]\n",
        "# print(np.unique(y_val, return_counts=True), np.unique(y_pred, return_counts=True))\n",
        "# print('acc:', metrics.accuracy_score(y_true=y_val, y_pred=y_pred))\n",
        "# print('roc auc:', metrics.roc_auc_score(y_val, y_pred_prob))\n",
        "# print('precision, recall, fscore:', metrics.precision_recall_fscore_support(y_val, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 1 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 2 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 3 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 4 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 5 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHbHm6Gjhgzu",
        "outputId": "63dea7dd-3e7a-4e29-d1e9-74690c70b37d"
      },
      "source": [
        "lr_under_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Accuracy': [0.5875626455848098,\n",
              "   0.5861922914019483,\n",
              "   0.5907807426231823,\n",
              "   0.5814626570662149,\n",
              "   0.5852746011577016],\n",
              "  'max': 0.5907807426231823,\n",
              "  'mean': 0.5862545875667713,\n",
              "  'min': 0.5814626570662149},\n",
              " {'AUC': [0.6184452789594044,\n",
              "   0.6170951967538966,\n",
              "   0.6254790096995716,\n",
              "   0.6161056279755838,\n",
              "   0.6166114840224713],\n",
              "  'max': 0.6254790096995716,\n",
              "  'mean': 0.6187473194821855,\n",
              "  'min': 0.6161056279755838},\n",
              " {'Precision': [0.3653370439084725,\n",
              "   0.3667322536703496,\n",
              "   0.37124202854539934,\n",
              "   0.36067073170731706,\n",
              "   0.36311728395061726],\n",
              "  'max': 0.37124202854539934,\n",
              "  'mean': 0.3654198683564312,\n",
              "  'min': 0.36067073170731706},\n",
              " {'Recall': [0.5762009266032675,\n",
              "   0.5908315045110949,\n",
              "   0.5961960497439649,\n",
              "   0.5769324554986589,\n",
              "   0.5737624969519629],\n",
              "  'max': 0.5961960497439649,\n",
              "  'mean': 0.5827846866617898,\n",
              "  'min': 0.5737624969519629},\n",
              " {'F_score': [0.4471567792601003,\n",
              "   0.45255883451624956,\n",
              "   0.45756526621128474,\n",
              "   0.4438608010505581,\n",
              "   0.4447594745298176],\n",
              "  'max': 0.45756526621128474,\n",
              "  'mean': 0.44918023111360206,\n",
              "  'min': 0.4438608010505581})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pnkU0gjNxl-"
      },
      "source": [
        "# Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzaW4k5qN5P7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7cf822-a62a-48ef-d827-ae0e264e2915"
      },
      "source": [
        "# random forest\n",
        "rf = RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced_subsample')\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_val)\n",
        "y_pred_prob = rf.predict_proba(X_val)[:,1]\n",
        "\n",
        "print(np.unique(y_val, return_counts=True), np.unique(y_pred, return_counts=True))\n",
        "print('acc:', metrics.accuracy_score(y_true=y_val, y_pred=y_pred))\n",
        "print('roc auc:', metrics.roc_auc_score(y_val, y_pred_prob))\n",
        "print('precision, recall, fscore:', metrics.precision_recall_fscore_support(y_val, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([10035,  4132])) (array([0, 1]), array([13773,   394]))\n",
            "acc: 0.7132773346509493\n",
            "roc auc: 0.6769577533810752\n",
            "precision, recall, fscore: (array([0.71683729, 0.58883249]), array([0.9838565 , 0.05614714]), array([0.82938508, 0.10251878]), array([10035,  4132]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Tw-FqBoAjd"
      },
      "source": [
        "## RF Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9eE6UDpnLHT",
        "outputId": "9f78e341-fd0a-46c9-b9cb-c21c764bdb2e"
      },
      "source": [
        "# Set a parameter dictionary for the GridSearch, these are just prelimiary \n",
        "params = { \n",
        "                'n_estimators' : [500,100, 1000],\n",
        "                'max_leaf_nodes': [50,100, None],\n",
        "                'max_features' : ('log2', 'sqrt')\n",
        "              }\n",
        "\n",
        "# Call the model function \n",
        "rf = RandomForestClassifier(n_jobs = -1, random_state =0, oob_score=True)\n",
        "# Set GridSearch on a cv = 5\n",
        "rf_cv_model = GridSearchCV(rf, params, cv = 3, scoring='roc_auc', verbose=1)\n",
        "\n",
        "# Fit the Gridsearch model to find the opitmal parameters\n",
        "rf_cv_model.fit(X_train_under, y_train_under)\n",
        "\n",
        "# Print out the best parameter set \n",
        "print(\"Best Parameters : \",rf_cv_model.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
            "Best Parameters :  {'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pienez-poFCl"
      },
      "source": [
        "## RF Model No Sampling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOr-tmH0PaEL",
        "outputId": "cf6b6989-c265-4c99-a6b8-6426a47038a2"
      },
      "source": [
        "# rf no sampler \n",
        "rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "rf_base_metrics = CV_Kfold_5(None, None, rf, X, y, ratio = 1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 1 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 2 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 3 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 4 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 5 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2234K36JR3Kb",
        "outputId": "bede3243-1e31-48c2-a43c-28d1c76c2995"
      },
      "source": [
        "rf_base_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Accuracy': [0.7180066351379968,\n",
              "   0.7200338839474799,\n",
              "   0.7167866723139913,\n",
              "   0.7194691514894819,\n",
              "   0.7173514047719892],\n",
              "  'max': 0.7200338839474799,\n",
              "  'mean': 0.7183295495321877,\n",
              "  'min': 0.7167866723139913},\n",
              " {'AUC': [0.6754266391923037,\n",
              "   0.6698802213798556,\n",
              "   0.6773562552988603,\n",
              "   0.6732086354569475,\n",
              "   0.6691994719037304],\n",
              "  'max': 0.6773562552988603,\n",
              "  'mean': 0.6730142446463395,\n",
              "  'min': 0.6691994719037304},\n",
              " {'Precision': [0.6086065573770492,\n",
              "   0.6256983240223464,\n",
              "   0.591002044989775,\n",
              "   0.626746506986028,\n",
              "   0.6025369978858351],\n",
              "  'max': 0.626746506986028,\n",
              "  'mean': 0.6109180862522068,\n",
              "  'min': 0.591002044989775},\n",
              " {'Recall': [0.07242136064374542,\n",
              "   0.08193123628383321,\n",
              "   0.07047061692270178,\n",
              "   0.07656669105096318,\n",
              "   0.06949524506217995],\n",
              "  'max': 0.08193123628383321,\n",
              "  'mean': 0.07417702999268472,\n",
              "  'min': 0.06949524506217995},\n",
              " {'F_score': [0.12943996513401612,\n",
              "   0.1448900388098318,\n",
              "   0.1259259259259259,\n",
              "   0.13646240764884834,\n",
              "   0.12461740271097507],\n",
              "  'max': 0.1448900388098318,\n",
              "  'mean': 0.13226714804591946,\n",
              "  'min': 0.12461740271097507})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58zwJO5WoKaO"
      },
      "source": [
        "## RF Model 1:1 Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Ge8r3vPjKO",
        "outputId": "e8ab6a0a-ad3b-4adf-bc8f-ac0c4ba82aef"
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "rf_under_metrics = CV_Kfold_5(RandomUnderSampler, True, rf, X, y, ratio = 1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 1 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 2 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 3 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 4 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 5 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIkmNKH2UkN_",
        "outputId": "e99a8fbd-5155-40f7-b74b-b1d297abd592"
      },
      "source": [
        "rf_under_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Accuracy': [0.6113503211689136,\n",
              "   0.609134547508118,\n",
              "   0.6125229422561062,\n",
              "   0.6117464351263588,\n",
              "   0.6092757306226175],\n",
              "  'max': 0.6125229422561062,\n",
              "  'mean': 0.6108059953364229,\n",
              "  'min': 0.609134547508118},\n",
              " {'AUC': [0.6718686660723934,\n",
              "   0.6706145605866187,\n",
              "   0.6736214362798842,\n",
              "   0.6729973533408122,\n",
              "   0.6673585725944007],\n",
              "  'max': 0.6736214362798842,\n",
              "  'mean': 0.6712921177748218,\n",
              "  'min': 0.6673585725944007},\n",
              " {'Precision': [0.39621805288816664,\n",
              "   0.3936611374407583,\n",
              "   0.3963560334528076,\n",
              "   0.3967832374206876,\n",
              "   0.39317640047675806],\n",
              "  'max': 0.3967832374206876,\n",
              "  'mean': 0.39523897233583566,\n",
              "  'min': 0.39317640047675806},\n",
              " {'Recall': [0.653986832479883,\n",
              "   0.648134601316752,\n",
              "   0.6471592294562302,\n",
              "   0.6556937332357962,\n",
              "   0.6435015849792733],\n",
              "  'max': 0.6556937332357962,\n",
              "  'mean': 0.6496951962935871,\n",
              "  'min': 0.6435015849792733},\n",
              " {'F_score': [0.49346826126954924,\n",
              "   0.48981848336865386,\n",
              "   0.49161804204871723,\n",
              "   0.49439235153520866,\n",
              "   0.48811615647831313],\n",
              "  'max': 0.49439235153520866,\n",
              "  'mean': 0.4914826589400884,\n",
              "  'min': 0.48811615647831313})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n77pXbglOpHw"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuXrZTT3OpQD"
      },
      "source": [
        "svc = SVC(C=4.17, gamma=0.03, kernel='linear', probability=True)\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred = svc.predict(X_val)\n",
        "y_pred_prob = svc.predict_proba(X_val)[:,1]\n",
        "\n",
        "print(np.unique(y_val, return_counts=True), np.unique(y_pred, return_counts=True))\n",
        "print('acc:', metrics.accuracy_score(y_true=y_val, y_pred=y_pred))\n",
        "print('roc auc:', metrics.roc_auc_score(y_val, y_pred_prob))\n",
        "print('precision, recall, fscore:', metrics.precision_recall_fscore_support(y_val, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l9W95UvN-rH"
      },
      "source": [
        "# ANN Model using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4C8y-6yOAST",
        "outputId": "7cc38176-f001-4412-f450-45b38c8bc35c"
      },
      "source": [
        "# Load pytorch packages\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import BatchSampler, SequentialSampler, RandomSampler\n",
        "\n",
        "# Check if cpu or gpu is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYBRKHI-OBew",
        "outputId": "47a74deb-ba95-44ef-dc70-89fd8f497194"
      },
      "source": [
        "# Define the ANN network using pytorch\n",
        "\n",
        "# function for initializing weights in model\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        # This is the default pytorch initialization\n",
        "        stdv = 1. / np.sqrt(m.weight.size(1))\n",
        "        nn.init.uniform_(m.weight, -stdv, stdv)\n",
        "        if m.bias is not None:\n",
        "            nn.init.uniform_(m.bias, -stdv, stdv)\n",
        "\n",
        "# ANN structure creation\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, in_size, h_sizes, sigmoid=True):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.in_size = in_size\n",
        "        self.h_sizes = h_sizes\n",
        "        self.layer_stack = nn.Sequential()\n",
        "        self.sigmoid = sigmoid\n",
        "\n",
        "        # Add first linear layer and ReLU Activation\n",
        "        self.layer_stack.add_module(\"linear_0\", \n",
        "            nn.Linear(self.in_size, self.h_sizes[0]))\n",
        "        self.layer_stack.add_module(\"relu_0\", nn.ReLU())\n",
        "\n",
        "        for i in range(len(h_sizes)-1):\n",
        "            # Add hidden linear layer and ReLU Activation\n",
        "            self.layer_stack.add_module(\"linear_\"+str(i+1), \n",
        "                nn.Linear(self.h_sizes[i], self.h_sizes[i+1]))\n",
        "            self.layer_stack.add_module(\"relu_\"+str(i+1), nn.ReLU())\n",
        "\n",
        "        if sigmoid:\n",
        "            # Add final linear layer, will output 1 node with sigmoid\n",
        "            self.layer_stack.add_module(\"linear_\"+str(len(h_sizes)), \n",
        "                nn.Linear(self.h_sizes[-1], 1))\n",
        "            self.layer_stack.add_module(\"sigmoid_out\", nn.Sigmoid())\n",
        "        else:\n",
        "            # Add final linear layer, will output 2 nodes\n",
        "            self.layer_stack.add_module(\"linear_\"+str(len(h_sizes)), \n",
        "                nn.Linear(self.h_sizes[-1], 2))\n",
        "            # No activation function is used as softmax is included within the \n",
        "            # CrossEntropyLoss() loss function\n",
        "    def forward(self, x):\n",
        "        output = self.layer_stack(x)\n",
        "        return output\n",
        "\n",
        "sigmoid_out = True\n",
        "\n",
        "# Create sample model\n",
        "model = NeuralNetwork(66,[32], sigmoid_out).to(device) # send to cpu or gpu\n",
        "model.apply(weights_init) # Apply weight initialization\n",
        "print('Printout of model:')\n",
        "print(model)\n",
        "\n",
        "# Define loss function\n",
        "if sigmoid_out:\n",
        "    # Use Binary cross entropy loss if using sigmoid on one output node\n",
        "    loss_fn = nn.BCELoss()\n",
        "else:\n",
        "    # Combined softmax with negative log likelihood loss\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use torchsummary\n",
        "print('Torchsummary Summary:')\n",
        "summary(model, input_size=(66,))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printout of model:\n",
            "NeuralNetwork(\n",
            "  (layer_stack): Sequential(\n",
            "    (linear_0): Linear(in_features=66, out_features=32, bias=True)\n",
            "    (relu_0): ReLU()\n",
            "    (linear_1): Linear(in_features=32, out_features=1, bias=True)\n",
            "    (sigmoid_out): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Torchsummary Summary:\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [-1, 32]           2,144\n",
            "              ReLU-2                   [-1, 32]               0\n",
            "            Linear-3                    [-1, 1]              33\n",
            "           Sigmoid-4                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 2,177\n",
            "Trainable params: 2,177\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.01\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARkfnKiXOb5s"
      },
      "source": [
        "## Loading the dataset by batches\n",
        "\n",
        "The following will split the dataset into batches for training, however this may be unnecessary as the entire dataset can fit into memory at once. This is just to show how it is done. Note that loading by batches as shown below is much slower due to looping over the ChurnDataset class many times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrWe9CcbOfBi"
      },
      "source": [
        "# Create custom PyTorch dataset\n",
        "class ChurnDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data, transform=None):\n",
        "        self.transform = transform\n",
        "        self.X_data = X_data.to_numpy()\n",
        "        self.y_data = y_data.to_numpy()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.X_data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        rows = self.X_data[idx].astype('float')\n",
        "        churn = self.y_data[idx].astype('float')\n",
        "        \n",
        "        rows = torch.FloatTensor(rows)\n",
        "        churn = torch.FloatTensor(churn)\n",
        "            \n",
        "        return (rows, churn)\n",
        "\n",
        "def getBatchLoader(X_data, y_data, batch_size = 1000, randomSample = False):\n",
        "    # Function to get pytorch batch dataloader from X, y data\n",
        "    pydataset = ChurnDataset(X_data, y_data)\n",
        "\n",
        "    # The BatchSampler will return multiple indices at once based on batch_size\n",
        "    if randomSample:\n",
        "        # RandomSampler uses a random order for the samples\n",
        "        return DataLoader(pydataset, \n",
        "                  sampler=BatchSampler(RandomSampler(pydataset), \n",
        "                  batch_size=batch_size, drop_last=False), num_workers=0)\n",
        "    else:\n",
        "        # The sequential sampler will ensure the result predictions \n",
        "        # are in the same order as the input arrays to the dataloader\n",
        "        return DataLoader(pydataset, \n",
        "                  sampler=BatchSampler(SequentialSampler(pydataset), \n",
        "                  batch_size=batch_size, drop_last=False), num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MMGmNjuNlON"
      },
      "source": [
        "## ANN Train and Test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kTwssh2OgD7"
      },
      "source": [
        "# The following is adapted from pytorch's quickstart guide available below:\n",
        "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "\n",
        "# Define the training function (one epoch)\n",
        "def ann_train_batch(dataloader, model, loss_fn, optimizer, threshold = 0.5):\n",
        "    # get total size of dataset\n",
        "    data_size = len(dataloader.dataset)\n",
        "    loader_size = len(dataloader)\n",
        "    \n",
        "    model.train()\n",
        "    total_loss, accuracy = 0, 0\n",
        "    if model.sigmoid:\n",
        "        y_prob_total = np.empty(0)\n",
        "    else:\n",
        "        y_prob_total = np.empty((0,2))\n",
        "    y_pred_total = np.empty(0)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Move X and y to proper device\n",
        "        X_train, y_train = X.to(device), y.to(device)\n",
        "        y_train = y_train.squeeze()\n",
        "        \n",
        "        if model.sigmoid == False:\n",
        "            y_data = y_data.long()\n",
        "\n",
        "        # Calculate the current loss\n",
        "        output = model(X_train).squeeze()\n",
        "        loss = loss_fn(output, y_train)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # Perform weight update\n",
        "        optimizer.zero_grad() # reset gradients\n",
        "        loss.backward() # calculate gradients\n",
        "        optimizer.step() # update weights\n",
        "\n",
        "        if model.sigmoid == True:\n",
        "            # Assume sigmoid output node\n",
        "            y_pred = (output > threshold).squeeze()\n",
        "            y_prob = output\n",
        "        else:\n",
        "            # Assume 2 node output requiring softmax\n",
        "            # Calculate the probabilities\n",
        "            y_prob = nn.functional.softmax(output,dim=1)\n",
        "            # get churn prediction\n",
        "            y_pred = torch.argmax(y_prob, dim=1).squeeze()\n",
        "            y_prob = y_prob[:,1]\n",
        "\n",
        "        # Calculate the prediction accuracy\n",
        "        accuracy += (y_pred == y_train).type(torch.float).sum().item()\n",
        "\n",
        "        y_prob = y_prob.cpu().detach().numpy()\n",
        "        y_pred = y_pred.cpu().detach().numpy()\n",
        "\n",
        "        y_prob_total = np.append(y_prob_total, y_prob, axis=0)\n",
        "        y_pred_total = np.append(y_pred_total, y_pred)\n",
        "\n",
        "    # Calculate final accuracy\n",
        "    accuracy /= data_size\n",
        "    total_loss /= loader_size\n",
        "\n",
        "    return total_loss, accuracy, y_prob_total, y_pred_total.astype('int')\n",
        "\n",
        "# Define the test function\n",
        "def ann_test_batch(dataloader, model, threshold = 0.5):\n",
        "    # get total size of dataset\n",
        "    data_size = len(dataloader.dataset)\n",
        "    loader_size = len(dataloader)\n",
        "    \n",
        "    model.eval()\n",
        "    total_loss, accuracy = 0, 0\n",
        "    if model.sigmoid:\n",
        "        y_prob_total = np.empty(0)\n",
        "    else:\n",
        "        y_prob_total = np.empty((0,2))\n",
        "    y_pred_total = np.empty(0)\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # Move X and y to proper device\n",
        "            X_test, y_test = X.to(device), y.to(device)\n",
        "            y_test = y_test.squeeze()\n",
        "\n",
        "            if model.sigmoid == False:\n",
        "                y_data = y_data.long()\n",
        "            \n",
        "            # Calculate the loss\n",
        "            output = model(X_test).squeeze()\n",
        "            total_loss += loss_fn(output, y_test).item()\n",
        "\n",
        "            if model.sigmoid == True:\n",
        "                # Assume sigmoid output node\n",
        "                y_pred = (output > threshold).squeeze()\n",
        "                y_prob = output\n",
        "            else:\n",
        "                # Assume 2 node output requiring softmax\n",
        "                # Calculate the probabilities\n",
        "                y_prob = nn.functional.softmax(output,dim=1)\n",
        "                # get churn prediction\n",
        "                y_pred = torch.argmax(y_prob, dim=1).squeeze()\n",
        "                y_prob = y_prob[:,1]\n",
        "\n",
        "            # Calculate the prediction accuracy\n",
        "            accuracy += (y_pred == y_test).type(torch.float).sum().item()\n",
        "\n",
        "            y_prob = y_prob.cpu().detach().numpy()\n",
        "            y_pred = y_pred.cpu().detach().numpy()\n",
        "\n",
        "            y_prob_total = np.append(y_prob_total, y_prob, axis=0)\n",
        "            y_pred_total = np.append(y_pred_total, y_pred)\n",
        "            \n",
        "    # Calculate final accuracy\n",
        "    accuracy /= data_size\n",
        "    total_loss /= loader_size\n",
        "    \n",
        "    return total_loss, accuracy, y_prob_total, y_pred_total.astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zgr_G5kNqDq"
      },
      "source": [
        "## ANN Hyperparameter Tuning\n",
        "\n",
        "See below for coarse tuning of the learning rate and momentum parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbaWyucRKWTx",
        "outputId": "5ccf95c0-1452-40ec-b9c9-cc8aace7c33f"
      },
      "source": [
        "from timeit import default_timer as timer # Allows timing of functions\n",
        "from datetime import timedelta # For nice formating of time measurements\n",
        "\n",
        "# Define threshold for sigmoid output\n",
        "sig_thresh = 0.5\n",
        "\n",
        "print('Sigmoid Threshold:',sig_thresh)\n",
        "\n",
        "# Make a train test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Get dataloaders for training and testing\n",
        "batch_size = 3000\n",
        "# Training dataloader will use random batch sampling\n",
        "train_dataloader_rdm = getBatchLoader(X_train, y_train, batch_size, True)\n",
        "# Test dataloader will use sequential sampling\n",
        "test_dataloader = getBatchLoader(X_val, y_val, batch_size, False)\n",
        "\n",
        "# Define optimization parameters to choose from:\n",
        "ann_params = {'learning_rate': [0.002, 0.005, 0.01, 0.02, 0.05, 0.1], \n",
        "              'momentum': [0.1, 0.5, 0.9],\n",
        "              }\n",
        "\n",
        "tuning_results = []\n",
        "\n",
        "epochs = 500\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "# Test learning rate and momentum\n",
        "for lr in ann_params['learning_rate']:\n",
        "  for momentum in ann_params['momentum']:\n",
        "\n",
        "    # Reinitialize model and weights\n",
        "    model = NeuralNetwork(66,[32], sigmoid=True).to(device) # send to cpu or gpu\n",
        "    model.apply(weights_init) # Apply weight initialization\n",
        "\n",
        "    # Define torch optimizer\n",
        "    # Stochastic gradient descent optimization with momentum\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    tuning_results.append({'learning_rate':lr, 'momentum':momentum,\n",
        "                           'best_acc': 0.0, 'best_epoch': 0, 'final_acc': 0.0})\n",
        "\n",
        "    # Train and test model\n",
        "    for i in range(epochs):\n",
        "      ann_train_batch(train_dataloader_rdm, model, loss_fn, optimizer, sig_thresh)\n",
        "      test_loss, test_accuracy, _, _ = ann_test_batch(test_dataloader, model, sig_thresh)\n",
        "\n",
        "      if test_accuracy > tuning_results[-1]['best_acc']:\n",
        "        tuning_results[-1]['best_acc'] = test_accuracy\n",
        "        tuning_results[-1]['best_epoch'] = i\n",
        "\n",
        "    tuning_results[-1]['final_acc'] = test_accuracy\n",
        "\n",
        "    elapsed = timedelta(seconds=(timer() - start_time))\n",
        "    print(f'{elapsed} -- Test #: {len(tuning_results)}')\n",
        "    print('Results:',tuning_results[-1])\n",
        "\n",
        "best_idx = -1\n",
        "best_acc = 0\n",
        "\n",
        "for i, result in enumerate(tuning_results):\n",
        "  if result['best_acc'] > best_acc:\n",
        "    best_acc = result['best_acc']\n",
        "    best_idx = i\n",
        "\n",
        "print('\\nBest Result:')\n",
        "print(tuning_results[best_idx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sigmoid Threshold: 0.5\n",
            "0:00:53.542353 -- Test #: 1\n",
            "Results: {'learning_rate': 0.002, 'momentum': 0.1, 'best_acc': 0.7083362744406014, 'best_epoch': 20, 'final_acc': 0.7083362744406014}\n",
            "0:01:48.340792 -- Test #: 2\n",
            "Results: {'learning_rate': 0.002, 'momentum': 0.5, 'best_acc': 0.7083362744406014, 'best_epoch': 0, 'final_acc': 0.7083362744406014}\n",
            "0:02:44.500217 -- Test #: 3\n",
            "Results: {'learning_rate': 0.002, 'momentum': 0.9, 'best_acc': 0.7088303804616362, 'best_epoch': 478, 'final_acc': 0.7086186207383356}\n",
            "0:03:38.423773 -- Test #: 4\n",
            "Results: {'learning_rate': 0.005, 'momentum': 0.1, 'best_acc': 0.7084068610150349, 'best_epoch': 3, 'final_acc': 0.7083362744406014}\n",
            "0:04:30.500043 -- Test #: 5\n",
            "Results: {'learning_rate': 0.005, 'momentum': 0.5, 'best_acc': 0.7083362744406014, 'best_epoch': 4, 'final_acc': 0.7083362744406014}\n",
            "0:05:22.516420 -- Test #: 6\n",
            "Results: {'learning_rate': 0.005, 'momentum': 0.9, 'best_acc': 0.710877391120209, 'best_epoch': 397, 'final_acc': 0.7103126985247405}\n",
            "0:06:14.403104 -- Test #: 7\n",
            "Results: {'learning_rate': 0.01, 'momentum': 0.1, 'best_acc': 0.7083362744406014, 'best_epoch': 0, 'final_acc': 0.7083362744406014}\n",
            "0:07:06.457589 -- Test #: 8\n",
            "Results: {'learning_rate': 0.01, 'momentum': 0.5, 'best_acc': 0.7087597938872027, 'best_epoch': 484, 'final_acc': 0.7086186207383356}\n",
            "0:07:58.346918 -- Test #: 9\n",
            "Results: {'learning_rate': 0.01, 'momentum': 0.9, 'best_acc': 0.7099597656525729, 'best_epoch': 248, 'final_acc': 0.709324486482671}\n",
            "0:08:50.196792 -- Test #: 10\n",
            "Results: {'learning_rate': 0.02, 'momentum': 0.1, 'best_acc': 0.7090421401849368, 'best_epoch': 489, 'final_acc': 0.7089009670360698}\n",
            "0:09:41.854326 -- Test #: 11\n",
            "Results: {'learning_rate': 0.02, 'momentum': 0.5, 'best_acc': 0.7096774193548387, 'best_epoch': 492, 'final_acc': 0.709324486482671}\n",
            "0:10:33.587320 -- Test #: 12\n",
            "Results: {'learning_rate': 0.02, 'momentum': 0.9, 'best_acc': 0.7115126702901108, 'best_epoch': 491, 'final_acc': 0.7111597374179431}\n",
            "0:11:25.338382 -- Test #: 13\n",
            "Results: {'learning_rate': 0.05, 'momentum': 0.1, 'best_acc': 0.71010093880144, 'best_epoch': 311, 'final_acc': 0.7098185925037058}\n",
            "0:12:17.479493 -- Test #: 14\n",
            "Results: {'learning_rate': 0.05, 'momentum': 0.5, 'best_acc': 0.7105950448224748, 'best_epoch': 159, 'final_acc': 0.7103832850991741}\n",
            "0:13:09.413345 -- Test #: 15\n",
            "Results: {'learning_rate': 0.05, 'momentum': 0.9, 'best_acc': 0.7106656313969083, 'best_epoch': 161, 'final_acc': 0.7080539281428673}\n",
            "0:14:01.042232 -- Test #: 16\n",
            "Results: {'learning_rate': 0.1, 'momentum': 0.1, 'best_acc': 0.710877391120209, 'best_epoch': 280, 'final_acc': 0.7097480059292722}\n",
            "0:14:52.938108 -- Test #: 17\n",
            "Results: {'learning_rate': 0.1, 'momentum': 0.5, 'best_acc': 0.7100303522270064, 'best_epoch': 167, 'final_acc': 0.7091833133338039}\n",
            "0:15:45.356474 -- Test #: 18\n",
            "Results: {'learning_rate': 0.1, 'momentum': 0.9, 'best_acc': 0.7110891508435095, 'best_epoch': 114, 'final_acc': 0.7053716383143926}\n",
            "\n",
            "Best Result:\n",
            "{'learning_rate': 0.02, 'momentum': 0.9, 'best_acc': 0.7115126702901108, 'best_epoch': 491, 'final_acc': 0.7111597374179431}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5KcAQEzvaBr"
      },
      "source": [
        "Based on the results above, the learning rate of 0.02 and momentum of 0.9 performed the best. Interestingly, the best epoch was close to the max of 500 tested, so more epochs may be beneficial.\n",
        "\n",
        "### Tuning the Number of Epochs\n",
        "\n",
        "See below for a more accurate tuning of the number of epochs with the chosen learning rate and momentum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "3siVd0OPv949",
        "outputId": "0abcdd3f-bfe6-4c67-8cb7-9121080300fa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# set chosen optimization parameters\n",
        "lr = 0.02\n",
        "momentum = 0.9\n",
        "sig_thresh = 0.5\n",
        "\n",
        "# Make a train test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Get dataloaders for training and testing\n",
        "batch_size = 1000\n",
        "# Training dataloader will use random batch sampling\n",
        "train_dataloader_rdm = getBatchLoader(X_train, y_train, batch_size, True)\n",
        "# Test dataloader will use sequential sampling\n",
        "test_dataloader = getBatchLoader(X_val, y_val, batch_size, False)\n",
        "\n",
        "# Reinitialize model and weights\n",
        "model = NeuralNetwork(66,[32], sigmoid=True).to(device) # send to cpu or gpu\n",
        "model.apply(weights_init) # Apply weight initialization\n",
        "\n",
        "# Define torch optimizer\n",
        "# Stochastic gradient descent optimization with momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "best_acc = 0\n",
        "best_epoch = 0\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# Train and test model\n",
        "for i in range(epochs):\n",
        "  # train model\n",
        "  train_loss, train_accuracy, _, _ = ann_train_batch(train_dataloader_rdm, model, loss_fn, optimizer, sig_thresh)\n",
        "  # test on test set\n",
        "  test_loss, test_accuracy, yprob_test, ypred_test = ann_test_batch(test_dataloader, model, sig_thresh)\n",
        "\n",
        "  train_losses.append(train_loss)\n",
        "  test_losses.append(test_loss)\n",
        "\n",
        "  if test_accuracy > best_acc:\n",
        "        best_acc = test_accuracy\n",
        "        best_epoch = i\n",
        "\n",
        "print(f'Best accuracy: {(best_acc*100):>0.2f}% at epoch {best_epoch}')\n",
        "print(f'Final accuracy: {(test_accuracy*100):>0.2f}% after {epochs} epochs')\n",
        "\n",
        "# Plot loss during training\n",
        "plt.plot(train_losses, label ='train loss')\n",
        "plt.plot(test_losses, label ='test loss')\n",
        "plt.title('Loss during training and testing')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 71.13% at epoch 237\n",
            "Final accuracy: 70.38% after 1000 epochs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkyGaECK9NuA"
      },
      "source": [
        "Based on the plot above, the test loss starts to increase after about 300-400 epochs, which indicates the model is starting to overfit the training data. Therefore only 300 epochs are needed.\n",
        "\n",
        "### Tuning the Sigmoid Threshold\n",
        "\n",
        "See below for tuning of the sigmoid threshold for the final result prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "6fTXz3dY9d9l",
        "outputId": "d4d55816-27aa-4baa-843b-799978e281b5"
      },
      "source": [
        "# set epochs to 300\n",
        "epochs = 300\n",
        "lr = 0.02\n",
        "momentum = 0.9\n",
        "\n",
        "# Reinitialize model and weights\n",
        "model = NeuralNetwork(66,[32], sigmoid=True).to(device) # send to cpu or gpu\n",
        "model.apply(weights_init) # Apply weight initialization\n",
        "\n",
        "# Define torch optimizer\n",
        "# Stochastic gradient descent optimization with momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "# Train and test model\n",
        "for i in range(epochs):\n",
        "  # train model\n",
        "  ann_train_batch(train_dataloader_rdm, model, loss_fn, optimizer, sig_thresh)\n",
        "\n",
        "# test on test set\n",
        "test_loss, test_accuracy, yprob_test, ypred_test = ann_test_batch(test_dataloader, model, sig_thresh)\n",
        "\n",
        "# Test varying thresholds on output probabilities to obtain best f-score\n",
        "sig_range = np.arange(0.01, 0.99, 0.01)\n",
        "f_scores = np.zeros_like(sig_range)\n",
        "\n",
        "for i, sig_thresh in enumerate(sig_range):\n",
        "    y_pred = yprob_test > sig_thresh\n",
        "\n",
        "    # Calculate f-score\n",
        "    # Setting zero_division=0 stops warnings from sklearn when there are\n",
        "    # divide by zero errors.\n",
        "    p_score, r_score, f_score, _ = metrics.precision_recall_fscore_support(y_val, y_pred, zero_division=0)\n",
        "    f_scores[i] = f_score[1]\n",
        "\n",
        "# Plot F-scores vs sigmoid threshold\n",
        "plt.plot(sig_range, f_scores)\n",
        "plt.title('F-score vs Sigmoid Threshold')\n",
        "plt.xlabel('Sigmoid Threshold')\n",
        "plt.ylabel('F-score')\n",
        "plt.show()\n",
        "\n",
        "best_f = np.amax(f_scores)\n",
        "best_thresh = sig_range[np.argmax(f_scores)]\n",
        "\n",
        "print(f'Best F-score: {best_f} using sig_thresh: {best_thresh}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Best F-score: 0.484578840208129 using sig_thresh: 0.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V5C2AlhJaC3"
      },
      "source": [
        "Based on the above chart, using a threshold of 0.27 on the output of the final sigmoid node produces the best f-score. Note however, that there would be some variability with this as the train-test split may not be balanced between the two classes. It may instead make sense to use the class ratio as the threshold.\n",
        "The class ratio shown below is the portion of the samples that represent churners.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWZjOL2uB_jE",
        "outputId": "bcde2efb-6879-4cd2-fc0b-63133838334a"
      },
      "source": [
        "class_ratio = y.to_numpy().mean()\n",
        "print('Class ratio', class_ratio)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class ratio 0.28949188914458357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGuHjDSiB-zX"
      },
      "source": [
        "We have decided to use the class ratio of 0.29 as the threshold value as we expect this to produce the most consistent result.\n",
        "\n",
        "## Testing Chosen ANN Params with Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbwiJ-NCJaLt"
      },
      "source": [
        "def ANN_CV_Kfold_5(sampler, sampling, ann_params, X, y, ratio = 1.0):\n",
        "    # Initialize the lists \n",
        "    acc_scores, auc_scores, p_scores, r_scores, f_scores, kf = [], [], [], [], [], 0\n",
        "\n",
        "    lr = ann_params['lr']\n",
        "    momentum = ann_params['momentum']\n",
        "    sig_thresh = ann_params['sig_thresh']\n",
        "    h_layers = ann_params['h_layers']\n",
        "    epochs = ann_params['epochs']\n",
        "    batch_size = ann_params['batch_size']\n",
        "\n",
        "    # Initialize the Kfolds\n",
        "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Iterate through Kfold indexes \n",
        "    for train_index, test_index in folds.split(X, y):\n",
        "\n",
        "      # Initialize the data based on Kfold index\n",
        "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "      # if sampling apply sampler\n",
        "      if sampling:\n",
        "        X_train, y_train = sampler(sampling_strategy=ratio).fit_resample(X_train, y_train)\n",
        "\n",
        "      # Create dataloaders\n",
        "      # Training dataloader will use random batch sampling\n",
        "      train_dataloader_rdm = getBatchLoader(X_train, y_train, batch_size, True)\n",
        "      # Test dataloader will use sequential sampling\n",
        "      test_dataloader = getBatchLoader(X_test, y_test, batch_size, False)\n",
        "      \n",
        "      # Reinitialize the model for each Kfold\n",
        "      model = NeuralNetwork(66,h_layers, sigmoid=True).to(device) # send to cpu or gpu\n",
        "      model.apply(weights_init) # Apply weight initialization\n",
        "\n",
        "      # Define torch optimizer\n",
        "      # Stochastic gradient descent optimization with momentum\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "      print('Training')\n",
        " \n",
        "      # Train the model\n",
        "      for i in range(epochs):\n",
        "        # train model\n",
        "        ann_train_batch(train_dataloader_rdm, model, loss_fn, optimizer, sig_thresh)\n",
        "\n",
        "      print('Predicting')\n",
        "      \n",
        "      # test on test set\n",
        "      test_loss, test_accuracy, y_pred_prob, y_pred = ann_test_batch(test_dataloader, model, sig_thresh)\n",
        "\n",
        "      print('Obtaining metric')\n",
        "\n",
        "      p_score, r_score, f_score, _ = metrics.precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "      # append metric scores to a list \n",
        "      acc_scores.append(metrics.accuracy_score(y_true=y_test, y_pred=y_pred))\n",
        "      auc_scores.append(metrics.roc_auc_score(y_test, y_pred_prob))\n",
        "      p_scores.append(p_score[1])\n",
        "      r_scores.append(r_score[1])\n",
        "      f_scores.append(f_score[1])\n",
        "\n",
        "      # Print the fold of each loop\n",
        "      kf += 1\n",
        "      print('KFold ' + str(kf) + ' completed')\n",
        "\n",
        "    # return the metric lists, min, max, and mean \n",
        "    mean_acc = np.mean(acc_scores)\n",
        "    mean_auc = np.mean(auc_scores)\n",
        "    mean_p = np.mean(p_scores)\n",
        "    mean_r = np.mean(r_scores)\n",
        "    mean_f = np.mean(f_scores)\n",
        "\n",
        "    min_acc = np.min(acc_scores)\n",
        "    min_auc = np.min(auc_scores)\n",
        "    min_p = np.min(p_scores)\n",
        "    min_r = np.min(r_scores)\n",
        "    min_f = np.min(f_scores)\n",
        "\n",
        "    max_acc = np.max(acc_scores)\n",
        "    max_auc = np.max(auc_scores)\n",
        "    max_p = np.max(p_scores)\n",
        "    max_r = np.max(r_scores)\n",
        "    max_f = np.max(f_scores)\n",
        "\n",
        "    # Create Dictionaries of the 5 metrics and their min, mean, max\n",
        "    acc = {'Accuracy': acc_scores, 'mean' : mean_acc, 'min' : min_acc, 'max' : max_acc}\n",
        "    auc = {'AUC': auc_scores, 'mean' : mean_auc, 'min' : min_auc, 'max' : max_auc}\n",
        "    precision = {'Precision': p_scores, 'mean' : mean_p, 'min' : min_p, 'max' : max_p}\n",
        "    recall = {'Recall': r_scores, 'mean' : mean_r, 'min' : min_r, 'max' : max_r}\n",
        "    f_score = {'F_score': f_scores, 'mean' : mean_f, 'min' : min_f, 'max' : max_f}\n",
        "\n",
        "    return acc, auc, precision, recall, f_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdsYbx4Spay1"
      },
      "source": [
        "### ANN without Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7IRJj-v_UVI",
        "outputId": "b27c802f-0b5b-4dcb-dee6-4df46b9dd6f0"
      },
      "source": [
        "# Testing the ANN without undersampling\n",
        "ann_params = {'lr': 0.02, 'momentum': 0.9, 'epochs':300, 'sig_thresh':0.29, \n",
        "              'batch_size':1000, 'h_layers': [32]}\n",
        "\n",
        "ann_base_metrics = ANN_CV_Kfold_5(None, None, ann_params, X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 1 completed\n",
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 2 completed\n",
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 3 completed\n",
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 4 completed\n",
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 5 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGIGZ9V5D9Li",
        "outputId": "3189f6bd-084d-418b-a7a0-4d9bc6dde3f3"
      },
      "source": [
        "ann_base_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Accuracy': [0.5754923413566739,\n",
              "   0.5938161795849216,\n",
              "   0.5922631653254271,\n",
              "   0.5472257518000847,\n",
              "   0.5744740928984894],\n",
              "  'max': 0.5938161795849216,\n",
              "  'mean': 0.5766543061931193,\n",
              "  'min': 0.5472257518000847},\n",
              " {'AUC': [0.6227763864081068,\n",
              "   0.6268574795407515,\n",
              "   0.6276361296052615,\n",
              "   0.6242631624022008,\n",
              "   0.6236958429074706],\n",
              "  'max': 0.6276361296052615,\n",
              "  'mean': 0.6250458001727582,\n",
              "  'min': 0.6227763864081068},\n",
              " {'Precision': [0.36107480029048655,\n",
              "   0.37031225482504315,\n",
              "   0.3702958030044913,\n",
              "   0.35646022092590296,\n",
              "   0.3649235945604935],\n",
              "  'max': 0.37031225482504315,\n",
              "  'mean': 0.36461333472128354,\n",
              "  'min': 0.35646022092590296},\n",
              " {'Recall': [0.6061936113143136,\n",
              "   0.5754693977078761,\n",
              "   0.5830285296269203,\n",
              "   0.7003169958546696,\n",
              "   0.6347232382345769],\n",
              "  'max': 0.7003169958546696,\n",
              "  'mean': 0.6199463545476712,\n",
              "  'min': 0.5754693977078761},\n",
              " {'F_score': [0.4525760058255962,\n",
              "   0.4506396792056521,\n",
              "   0.45292669066111013,\n",
              "   0.4724461260075671,\n",
              "   0.4634146341463415],\n",
              "  'max': 0.4724461260075671,\n",
              "  'mean': 0.4584006271692534,\n",
              "  'min': 0.4506396792056521})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjG2QFy0pcvO"
      },
      "source": [
        "### ANN with undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9WeT5QK_ayN",
        "outputId": "e9ce763a-e41f-4b4d-d00a-e87fd4fba9d0"
      },
      "source": [
        "# Testing the ANN with undersampling\n",
        "# Note that when undersampling the data, it makes sense to use a sigmoid \n",
        "# threshold of 0.5 as the training data is no longer imbalanced\n",
        "ann_params = {'lr': 0.02, 'momentum': 0.9, 'epochs':300, 'sig_thresh': 0.5, \n",
        "              'batch_size':1000, 'h_layers': [32]}\n",
        "\n",
        "ann_under_metrics = ANN_CV_Kfold_5(RandomUnderSampler, True, ann_params, X, y, ratio = 1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 1 completed\n",
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 2 completed\n",
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 3 completed\n",
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 4 completed\n",
            "Training\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 5 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB9S65Z8D_sk",
        "outputId": "38e0003e-c9b0-408b-8b09-ea5607190416"
      },
      "source": [
        "ann_under_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Accuracy': [0.5884096844780122,\n",
              "   0.6137935902866017,\n",
              "   0.5995340957221517,\n",
              "   0.5782154454327263,\n",
              "   0.572850487081745],\n",
              "  'max': 0.6137935902866017,\n",
              "  'mean': 0.5905606606002475,\n",
              "  'min': 0.572850487081745},\n",
              " {'AUC': [0.614625209777381,\n",
              "   0.6110456502376106,\n",
              "   0.6240149949493132,\n",
              "   0.6062217871084961,\n",
              "   0.6142584660327234],\n",
              "  'max': 0.6240149949493132,\n",
              "  'mean': 0.6140332216211049,\n",
              "  'min': 0.6062217871084961},\n",
              " {'Precision': [0.36300285080772887,\n",
              "   0.37568058076225047,\n",
              "   0.37649277184160906,\n",
              "   0.3529965484781927,\n",
              "   0.3552123552123552],\n",
              "  'max': 0.37649277184160906,\n",
              "  'mean': 0.36467702142042724,\n",
              "  'min': 0.3529965484781927},\n",
              " {'Recall': [0.5588880760790051,\n",
              "   0.5047549378200439,\n",
              "   0.5842477444525725,\n",
              "   0.548646671543526,\n",
              "   0.5832723725920507],\n",
              "  'max': 0.5842477444525725,\n",
              "  'mean': 0.5559619604974395,\n",
              "  'min': 0.5047549378200439},\n",
              " {'F_score': [0.44013442150744125,\n",
              "   0.430756424929768,\n",
              "   0.45790731008122315,\n",
              "   0.42959427207637235,\n",
              "   0.44153207198892475],\n",
              "  'max': 0.45790731008122315,\n",
              "  'mean': 0.43998490011674585,\n",
              "  'min': 0.42959427207637235})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iebdY-PSFcay"
      },
      "source": [
        "# ANN Hybrid Model\n",
        "\n",
        "See below for testing of an ANN hybrid structure. This will perform 5-fold cross-validation. For each fold, it will train an ANN and then test on the training data. The correctly predicted values training samples will then be used to train a second ANN, thereby removing outliers from the training data. This second ANN will then be used for the final prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dnf0DYaFdAq"
      },
      "source": [
        "def ANN_Hybrid_Kfold(sampler, sampling, ann_params, X, y, ratio = 1.0):\n",
        "    # Initialize the lists \n",
        "    acc_scores, auc_scores, p_scores, r_scores, f_scores, kf = [], [], [], [], [], 0\n",
        "\n",
        "    lr = ann_params['lr']\n",
        "    momentum = ann_params['momentum']\n",
        "    sig_thresh = ann_params['sig_thresh']\n",
        "    h_layers = ann_params['h_layers']\n",
        "    epochs = ann_params['epochs']\n",
        "    batch_size = ann_params['batch_size']\n",
        "\n",
        "    # Initialize the Kfolds\n",
        "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Iterate through Kfold indexes \n",
        "    for train_index, test_index in folds.split(X, y):\n",
        "\n",
        "      # Initialize the data based on Kfold index\n",
        "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "      # if sampling apply sampler\n",
        "      if sampling:\n",
        "        X_train, y_train = sampler(sampling_strategy=ratio).fit_resample(X_train, y_train)\n",
        "\n",
        "      # Create dataloaders\n",
        "      # Training dataloader will use random batch sampling\n",
        "      train_dataloader_rdm = getBatchLoader(X_train, y_train, batch_size, True)\n",
        "      # This training loader will be sequential so results are in the proper \n",
        "      # order when testing on the training set\n",
        "      train_dataloader = getBatchLoader(X_train, y_train, batch_size, False)\n",
        "      # Test dataloader will use sequential sampling\n",
        "      test_dataloader = getBatchLoader(X_test, y_test, batch_size, False)\n",
        "      \n",
        "      # Reinitialize the model for each Kfold\n",
        "      model = NeuralNetwork(66,h_layers, sigmoid=True).to(device) # send to cpu or gpu\n",
        "      model.apply(weights_init) # Apply weight initialization\n",
        "\n",
        "      # Define torch optimizer\n",
        "      # Stochastic gradient descent optimization with momentum\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "      print('Training')\n",
        " \n",
        "      for i in range(epochs):\n",
        "        # train model\n",
        "        ann_train_batch(train_dataloader_rdm, model, loss_fn, optimizer, sig_thresh)\n",
        "\n",
        "      print('Predicting on Train set')\n",
        "      \n",
        "      # Test on the training set\n",
        "      _, _, y_prob_train, y_pred_train = ann_test_batch(train_dataloader, model, sig_thresh)\n",
        "\n",
        "      # Gather correctly predicted training data\n",
        "      correct = np.equal(y_train.to_numpy(), y_pred_train)\n",
        "      \n",
        "      # Create subset of training set\n",
        "      X_train2 = X_train.loc[correct]\n",
        "      y_train2 = y_train.loc[correct]\n",
        "\n",
        "      print(f'Correctly predicted: {len(y_train2)} / {len(y_train)}')\n",
        "      print(f'New train churn ratio: {y_train2.to_numpy().mean()}')\n",
        "\n",
        "      # if sampling apply sampler on subset again\n",
        "      if sampling:\n",
        "        X_train2, y_train2 = sampler(sampling_strategy=ratio).fit_resample(X_train2, y_train2)\n",
        "\n",
        "      train_dataloader2 = getBatchLoader(X_train2, y_train2, batch_size, True)\n",
        "\n",
        "      # sig_thresh = y_train2.to_numpy().mean()\n",
        "\n",
        "      print('Training second ANN')\n",
        "\n",
        "      model2 = NeuralNetwork(66,h_layers, sigmoid=True).to(device) # send to cpu or gpu\n",
        "      model2.apply(weights_init) # Apply weight initialization\n",
        "\n",
        "      optimizer2 = torch.optim.SGD(model2.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "      for i in range(epochs):\n",
        "        # train model\n",
        "        ann_train_batch(train_dataloader2, model2, loss_fn, optimizer2, sig_thresh)\n",
        "\n",
        "      print('Predicting on Test set')\n",
        "\n",
        "      test_loss, test_accuracy, y_pred_prob, y_pred = ann_test_batch(test_dataloader, model2, sig_thresh)\n",
        "\n",
        "      print('Obtaining metric')\n",
        "\n",
        "      p_score, r_score, f_score, _ = metrics.precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "      # append metric scores to a list \n",
        "      acc_scores.append(metrics.accuracy_score(y_true=y_test, y_pred=y_pred))\n",
        "      auc_scores.append(metrics.roc_auc_score(y_test, y_pred_prob))\n",
        "      p_scores.append(p_score[1])\n",
        "      r_scores.append(r_score[1])\n",
        "      f_scores.append(f_score[1])\n",
        "\n",
        "      # Print the fold of each loop\n",
        "      kf += 1\n",
        "      print('KFold ' + str(kf) + ' completed')\n",
        "\n",
        "    # return the metric lists, min, max, and mean \n",
        "    mean_acc = np.mean(acc_scores)\n",
        "    mean_auc = np.mean(auc_scores)\n",
        "    mean_p = np.mean(p_scores)\n",
        "    mean_r = np.mean(r_scores)\n",
        "    mean_f = np.mean(f_scores)\n",
        "\n",
        "    min_acc = np.min(acc_scores)\n",
        "    min_auc = np.min(auc_scores)\n",
        "    min_p = np.min(p_scores)\n",
        "    min_r = np.min(r_scores)\n",
        "    min_f = np.min(f_scores)\n",
        "\n",
        "    max_acc = np.max(acc_scores)\n",
        "    max_auc = np.max(auc_scores)\n",
        "    max_p = np.max(p_scores)\n",
        "    max_r = np.max(r_scores)\n",
        "    max_f = np.max(f_scores)\n",
        "\n",
        "    # Create Dictionaries of the 5 metrics and their min, mean, max\n",
        "    acc = {'Accuracy': acc_scores, 'mean' : mean_acc, 'min' : min_acc, 'max' : max_acc}\n",
        "    auc = {'AUC': auc_scores, 'mean' : mean_auc, 'min' : min_auc, 'max' : max_auc}\n",
        "    precision = {'Precision': p_scores, 'mean' : mean_p, 'min' : min_p, 'max' : max_p}\n",
        "    recall = {'Recall': r_scores, 'mean' : mean_r, 'min' : min_r, 'max' : max_r}\n",
        "    f_score = {'F_score': f_scores, 'mean' : mean_f, 'min' : min_f, 'max' : max_f}\n",
        "\n",
        "    return acc, auc, precision, recall, f_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW-qqXwIpTfX"
      },
      "source": [
        "## ANN Hybrid Model without Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVFY1NnCKOxr",
        "outputId": "770db703-877b-44ca-970f-6726f4780a73"
      },
      "source": [
        "# Testing the hybrid ANN without a sampling method\n",
        "ann_params = {'lr': 0.02, 'momentum': 0.9, 'epochs':300, 'sig_thresh':0.29, \n",
        "              'batch_size':1000, 'h_layers': [32]}\n",
        "\n",
        "hybrid_base_metrics = ANN_Hybrid_Kfold(None, None, ann_params, X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 31691 / 56664\n",
            "New train churn ratio: 0.37158814805465273\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 1 completed\n",
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 31507 / 56665\n",
            "New train churn ratio: 0.36896562668613325\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 2 completed\n",
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 33636 / 56665\n",
            "New train churn ratio: 0.30960875252705433\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 3 completed\n",
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 32507 / 56665\n",
            "New train churn ratio: 0.34706370935490816\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 4 completed\n",
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 34031 / 56665\n",
            "New train churn ratio: 0.30442831535952514\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 5 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1P-I08UKO3p",
        "outputId": "6ac1231d-239e-4714-f412-ead84a7e8c96"
      },
      "source": [
        "hybrid_base_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Accuracy': [0.5413990259052728,\n",
              "   0.540872511647607,\n",
              "   0.5736269942114923,\n",
              "   0.5554143724410561,\n",
              "   0.5511082874488211],\n",
              "  'max': 0.5736269942114923,\n",
              "  'mean': 0.5524842383308499,\n",
              "  'min': 0.540872511647607},\n",
              " {'AUC': [0.6187160473622204,\n",
              "   0.6173720972178766,\n",
              "   0.6243402642637536,\n",
              "   0.6185625669190252,\n",
              "   0.6204554933289628],\n",
              "  'max': 0.6243402642637536,\n",
              "  'mean': 0.6198892938183678,\n",
              "  'min': 0.6173720972178766},\n",
              " {'Precision': [0.3527531956735497,\n",
              "   0.34990630855715177,\n",
              "   0.3643107067879636,\n",
              "   0.35604770017035775,\n",
              "   0.352533960292581],\n",
              "  'max': 0.3643107067879636,\n",
              "  'mean': 0.35511037429632075,\n",
              "  'min': 0.34990630855715177},\n",
              " {'Recall': [0.6998293099244087,\n",
              "   0.6830041453304072,\n",
              "   0.6347232382345769,\n",
              "   0.6625213362594489,\n",
              "   0.6581321628871007],\n",
              "  'max': 0.6998293099244087,\n",
              "  'mean': 0.6676420385271885,\n",
              "  'min': 0.6347232382345769},\n",
              " {'F_score': [0.4690692163111875,\n",
              "   0.4627457459111185,\n",
              "   0.46292014938644854,\n",
              "   0.46317763382202526,\n",
              "   0.4591307306285618],\n",
              "  'max': 0.4690692163111875,\n",
              "  'mean': 0.46340869521186834,\n",
              "  'min': 0.4591307306285618})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VErfP__5pOMm"
      },
      "source": [
        "## ANN Hybrid Model with Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GlhmO_CUmMN",
        "outputId": "68361e1a-c6bc-40e5-cfbf-bdbacfe8ce4d"
      },
      "source": [
        "# Testing the Hybrid ANN with undersampling\n",
        "# Note that when undersampling the data, it makes sense to use a sigmoid \n",
        "# threshold of 0.5 as the training data is no longer imbalanced\n",
        "ann_params = {'lr': 0.02, 'momentum': 0.9, 'epochs':300, 'sig_thresh': 0.5, \n",
        "              'batch_size':1000, 'h_layers': [32]}\n",
        "\n",
        "hybrid_under_metrics = ANN_Hybrid_Kfold(RandomUnderSampler, True, ann_params, X, y, ratio = 1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 19566 / 32808\n",
            "New train churn ratio: 0.4867116426454053\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 1 completed\n",
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 19798 / 32808\n",
            "New train churn ratio: 0.5347509849479746\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 2 completed\n",
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 19535 / 32808\n",
            "New train churn ratio: 0.6505246992577425\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 3 completed\n",
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 19662 / 32808\n",
            "New train churn ratio: 0.4711626487641135\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 4 completed\n",
            "Training\n",
            "Predicting on Train set\n",
            "Correctly predicted: 19844 / 32808\n",
            "New train churn ratio: 0.5334609957669825\n",
            "Training second ANN\n",
            "Predicting on Test set\n",
            "Obtaining metric\n",
            "KFold 5 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcs8G7ewUmeM",
        "outputId": "587e653e-be0f-4e9b-d6cf-ae54c55e5b1f"
      },
      "source": [
        "hybrid_under_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Accuracy': [0.591233147455354,\n",
              "   0.5626147112805309,\n",
              "   0.48792884371029227,\n",
              "   0.5863334745164478,\n",
              "   0.5699562332345052],\n",
              "  'max': 0.591233147455354,\n",
              "  'mean': 0.559613282039426,\n",
              "  'min': 0.48792884371029227},\n",
              " {'AUC': [0.6091045502996487,\n",
              "   0.6132500730135853,\n",
              "   0.6152109556597066,\n",
              "   0.610402997439346,\n",
              "   0.6117192891414293],\n",
              "  'max': 0.6152109556597066,\n",
              "  'mean': 0.6119375731107433,\n",
              "  'min': 0.6091045502996487},\n",
              " {'Precision': [0.3625122030589001,\n",
              "   0.3554175293305728,\n",
              "   0.3333333333333333,\n",
              "   0.35761696616480493,\n",
              "   0.35727598566308244],\n",
              "  'max': 0.3625122030589001,\n",
              "  'mean': 0.3532312035101387,\n",
              "  'min': 0.3333333333333333},\n",
              " {'Recall': [0.543282126310656,\n",
              "   0.6278956352109242,\n",
              "   0.7688368690563278,\n",
              "   0.5386491099731773,\n",
              "   0.6076566691050963],\n",
              "  'max': 0.7688368690563278,\n",
              "  'mean': 0.6172640819312363,\n",
              "  'min': 0.5386491099731773},\n",
              " {'F_score': [0.4348589831170099,\n",
              "   0.45390445972148774,\n",
              "   0.46504424778761055,\n",
              "   0.4298501654018292,\n",
              "   0.44998194293968946],\n",
              "  'max': 0.46504424778761055,\n",
              "  'mean': 0.44672795979352536,\n",
              "  'min': 0.4298501654018292})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPMGix6pnmo_"
      },
      "source": [
        "#XGBoost\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhzU_cBmno56"
      },
      "source": [
        "# Necessary libraries \n",
        "\n",
        "# Import functions from xgboost and sklearn for opitimization\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1QzAXSdol47"
      },
      "source": [
        "## XGBoost Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZOf-ROxn-2i"
      },
      "source": [
        "# Set a parameter dictionary for the GridSearch, these are just prelimiary \n",
        "params = {'n_estimators': [100, 125, 150, 175, 200, 225, 250], \n",
        "              'learning_rate': [0.1, 0.01, 0.02, 0.05], \n",
        "              'max_depth': [2, 4, 6, 8, 10], \n",
        "         }\n",
        "\n",
        "# Call the model function \n",
        "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'auc')\n",
        "\n",
        "# Set GridSearch on a cv = 5\n",
        "xgb_cv_model = GridSearchCV(xgb, params, cv = 5, verbose = 2)\n",
        "\n",
        "# Fit the Gridsearch model to find the opitmal parameters\n",
        "xgb_cv_model.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Print out the best parameter set \n",
        "print(\"Best Parameters : \",xgb_cv_model.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A5m4iv_oEo5",
        "outputId": "9b633138-35b8-45be-f341-023c206614c0"
      },
      "source": [
        "# Best parameter set on the previous cell2cell, learning_rate = 0.05, max_depth = 10, n_estimators = 200\n",
        "\n",
        "# Will not re-run until data ratio is sorted \n",
        "\n",
        "# Fit a model with the ideal parameters\n",
        "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'auc', learning_rate = 0.05, max_depth = 10, n_estimators = 200)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict and show the acc, roc, precision, recall, and fscore \n",
        "y_pred = xgb.predict(X_val)\n",
        "y_pred_prob = xgb.predict_proba(X_val)[:,1]\n",
        "\n",
        "print('acc:', metrics.accuracy_score(y_true=y_val, y_pred=y_pred))\n",
        "print('roc auc:', metrics.roc_auc_score(y_val, y_pred_prob))\n",
        "print('precision, recall, fscore:', metrics.precision_recall_fscore_support(y_val, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 0.7208300981153385\n",
            "roc auc: 0.6815979984864206\n",
            "precision, recall, fscore: (array([0.7345679 , 0.57332229]), array([0.94867962, 0.16747338]), array([0.82800609, 0.25922457]), array([10035,  4132]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvX2kPpV7J6E"
      },
      "source": [
        "# XGB Undersampling 1:1 5 Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5xA-ywHpqyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7381de-1995-4c8e-e9b2-ef9bda4e5ff8"
      },
      "source": [
        "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'auc', learning_rate = 0.05, max_depth = 10, n_estimators = 200)\n",
        "results_xgb = CV_Kfold_5(RandomUnderSampler, False, xgb, X, y, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 1 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 2 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 3 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 4 completed\n",
            "Fitting\n",
            "Predicting\n",
            "Obtaining metric\n",
            "KFold 5 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fobAOYw77cm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb54498-2e3c-4bc2-8fa3-8d3d43261119"
      },
      "source": [
        "results_xgb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Accuracy': [0.7199830592221359,\n",
              "   0.72285754623747,\n",
              "   0.7203868417337287,\n",
              "   0.7160807567414937,\n",
              "   0.7201044755047297],\n",
              "  'max': 0.72285754623747,\n",
              "  'mean': 0.7198825358879116,\n",
              "  'min': 0.7160807567414937},\n",
              " {'AUC': [0.6765847842668042,\n",
              "   0.6778706997542068,\n",
              "   0.6792240100405641,\n",
              "   0.6751928727596397,\n",
              "   0.6748762281938916],\n",
              "  'max': 0.6792240100405641,\n",
              "  'mean': 0.6767497190030213,\n",
              "  'min': 0.6748762281938916},\n",
              " {'Precision': [0.5544715447154471,\n",
              "   0.5720164609053497,\n",
              "   0.5571895424836601,\n",
              "   0.5349248452696729,\n",
              "   0.5597539543057997],\n",
              "  'max': 0.5720164609053497,\n",
              "  'mean': 0.555671269535986,\n",
              "  'min': 0.5349248452696729},\n",
              " {'Recall': [0.16630090221897098,\n",
              "   0.16947086076566692,\n",
              "   0.16630090221897098,\n",
              "   0.14752499390392587,\n",
              "   0.15532796878810046],\n",
              "  'max': 0.16947086076566692,\n",
              "  'mean': 0.16098512557912703,\n",
              "  'min': 0.14752499390392587},\n",
              " {'F_score': [0.2558619395985744,\n",
              "   0.2614747930775019,\n",
              "   0.25615023474178406,\n",
              "   0.2312691131498471,\n",
              "   0.24317617866004962],\n",
              "  'max': 0.2614747930775019,\n",
              "  'mean': 0.24958645184555145,\n",
              "  'min': 0.2312691131498471})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyMHpVDZW7XO"
      },
      "source": [
        "XGB with Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLLEaPAOW6Z_"
      },
      "source": [
        "({'Accuracy': [0.6175619397190655,\n",
        "   0.613440632500353,\n",
        "   0.6179584921643372,\n",
        "   0.6139347734011013,\n",
        "   0.6219116193703234],\n",
        "  'max': 0.6219116193703234,\n",
        "  'mean': 0.6169614914310361,\n",
        "  'min': 0.613440632500353},\n",
        " {'AUC': [0.6697280998324978,\n",
        "   0.671495520521148,\n",
        "   0.6781137190073835,\n",
        "   0.6712732757679812,\n",
        "   0.6692056860836167],\n",
        "  'max': 0.6781137190073835,\n",
        "  'mean': 0.6719632602425254,\n",
        "  'min': 0.6692056860836167},\n",
        " {'Precision': [0.39911138348398956,\n",
        "   0.3971885748467175,\n",
        "   0.4005461993627674,\n",
        "   0.3973897389738974,\n",
        "   0.40097838093735205],\n",
        "  'max': 0.40097838093735205,\n",
        "  'mean': 0.39904285552094476,\n",
        "  'min': 0.3971885748467175},\n",
        " {'Recall': [0.6352109241648378,\n",
        "   0.6476469153864911,\n",
        "   0.6437454279444038,\n",
        "   0.6459400146305779,\n",
        "   0.6196049743964887],\n",
        "  'max': 0.6476469153864911,\n",
        "  'mean': 0.6384296513045599,\n",
        "  'min': 0.6196049743964887},\n",
        " {'F_score': [0.4902145276627776,\n",
        "   0.4923989618094179,\n",
        "   0.49382716049382713,\n",
        "   0.4920590693786571,\n",
        "   0.48687488024525766],\n",
        "  'max': 0.49382716049382713,\n",
        "  'mean': 0.49107491991798746,\n",
        "  'min': 0.48687488024525766})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Am2hoP7oO3"
      },
      "source": [
        "# SVM Undersampling 1:1 5 fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_j2_RN17sJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23abf14e-a004-45a2-afe2-926ca5df8a12"
      },
      "source": [
        "svc = SVC(C=4.17, gamma=0.03, kernel='linear', probability=True)\n",
        "results_svm = CV_Kfold_5(RandomUnderSampler, False, svc, X, y, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6v6KV5_v_Wt"
      },
      "source": [
        "({'Accuracy': [0.5848803557563351,\n",
        "   0.5751800084709868,\n",
        "   0.5703797825780037,\n",
        "   0.5775095298602287,\n",
        "   0.5833686291119582],\n",
        "  'max': 0.5848803557563351,\n",
        "  'mean': 0.5782636611555025,\n",
        "  'min': 0.5703797825780037},\n",
        " {'AUC': [0.6132306828576846,\n",
        "   0.6128685974717131,\n",
        "   0.6192955978773912,\n",
        "   0.6141279924819325,\n",
        "   0.6148409151778982],\n",
        "  'max': 0.6192955978773912,\n",
        "  'mean': 0.6148727571733239,\n",
        "  'min': 0.6128685974717131},\n",
        " {'Precision': [0.3629504157684016,\n",
        "   0.36066288704753596,\n",
        "   0.3599943574552123,\n",
        "   0.3615113201999412,\n",
        "   0.36186531676637523],\n",
        "  'max': 0.3629504157684016,\n",
        "  'mean': 0.3613968594474932,\n",
        "  'min': 0.3599943574552123},\n",
        " {'Recall': [0.5747378688124848,\n",
        "   0.6049743964886612,\n",
        "   0.6222872470129237,\n",
        "   0.5996098512557912,\n",
        "   0.5752255547427457],\n",
        "  'max': 0.6222872470129237,\n",
        "  'mean': 0.5953669836625213,\n",
        "  'min': 0.5747378688124848},\n",
        " {'F_score': [0.4449268522888155,\n",
        "   0.45191256830601084,\n",
        "   0.45612153708668457,\n",
        "   0.4510685132532331,\n",
        "   0.444256120527307],\n",
        "  'max': 0.45612153708668457,\n",
        "  'mean': 0.4496571182924102,\n",
        "  'min': 0.444256120527307})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP5h_2doXZn_"
      },
      "source": [
        "SVM No Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw0pwTke2IND"
      },
      "source": [
        "({'Accuracy': [0.7104538716736076,\n",
        "   0.710856981505012,\n",
        "   0.7117746717492588,\n",
        "   0.710856981505012,\n",
        "   0.7105040237187632],\n",
        "  'max': 0.7117746717492588,\n",
        "  'mean': 0.7108893060303307,\n",
        "  'min': 0.7104538716736076},\n",
        " {'AUC': [0.5317923649778324,\n",
        "   0.5030795682731836,\n",
        "   0.515765374371632,\n",
        "   0.5522395819516474,\n",
        "   0.530016051481028],\n",
        "  'max': 0.5522395819516474,\n",
        "  'mean': 0.5265785882110647,\n",
        "  'min': 0.5030795682731836},\n",
        " {'Precision': [0.48148148148148145,\n",
        "   0.5190839694656488,\n",
        "   0.5833333333333334,\n",
        "   0.5135135135135135,\n",
        "   0.5],\n",
        "  'max': 0.5833333333333334,\n",
        "  'mean': 0.5194824595587955,\n",
        "  'min': 0.48148148148148145},\n",
        " {'Recall': [0.0031699585466959277,\n",
        "   0.016581321628871007,\n",
        "   0.015362106803218726,\n",
        "   0.02316508168739332,\n",
        "   0.02365276761765423],\n",
        "  'max': 0.02365276761765423,\n",
        "  'mean': 0.016386247256766642,\n",
        "  'min': 0.0031699585466959277},\n",
        " {'F_score': [0.0062984496124031,\n",
        "   0.032136105860113416,\n",
        "   0.029935851746258017,\n",
        "   0.04433037797480168,\n",
        "   0.045168800931315485],\n",
        "  'max': 0.045168800931315485,\n",
        "  'mean': 0.031573917224978335,\n",
        "  'min': 0.0062984496124031})"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}